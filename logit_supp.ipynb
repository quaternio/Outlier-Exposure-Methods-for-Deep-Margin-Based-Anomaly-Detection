{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Anomaly Detection and Continual Learning with Coresets: Experiment Overview\n",
    "\n",
    "One of the primary issues associated with training a good anomaly detector via the finetuning of a classifier backbone is \\textit{catastrophic forgetting}. When a trained classifier moves from the classification task $T_1$ to the novelty detection task $T_2$, we want to continue to perform well on $T_1$ while learning how to do well on task $T_2$.\n",
    "\n",
    "One proposed method for doing this is the use of \\textit{exemplars} or \\textit{coresets}. One applicable coreset method that has been presented recently was the method by Borsos et al., presented at Neurips 2021, where a coreset is carefully selected to preserve performance on previous tasks. This method specifically associates weights with each training example and the goal is to construct a coreset of size $m$ to minimize\n",
    "\n",
    "\\begin{equation}\n",
    "  L(\\theta,w)=\\sum_{i=1}w_i\\ell_i(\\theta)\n",
    "\\end{equation}\n",
    "\n",
    "To omit an example $i$ from the set of exemplars, one can simply set $w_i=0$. We then find our weights $\\hat{w}$ via\n",
    "\n",
    "\\begin{equation} \\tag{2}\n",
    "  \\hat{w}\\in \\argmin_{w\\in\\mathbb{R}_{+}^n,\\|w\\|_0\\leq m}L(\\theta^*(w))\\;\\mathrm{s.t.}\\;\\theta^*(w)\\in\\argmin_{\\theta}L(\\theta,w)\n",
    "\\end{equation}\n",
    "\n",
    "We want to train a good anomaly detector while retaining training set classification performance using this mechanism.\n",
    "\n",
    "### Finetuning a Classifier to get an Anomaly Detector\n",
    "Since we are dealing with a batched online learning scenario, we want to extract information from each new set of labeled examples that will be received during round $t$. This will be done by finetuning the backbone network via outlier exposure with uniform cross-entropy loss regularization term. Our fine-tuning objective is\n",
    "\n",
    "\\begin{equation} \\tag{3}\n",
    "  \\mathbb{E}_{(x,y)~\\mathcal{D}_{in}}[-\\log f_y(x)]+\\lambda\\mathbb{E}_{x~\\mathcal{D}_{out}^{OE}}[H(\\mathcal{U};f(x))]\n",
    "\\end{equation}\n",
    "\n",
    "Anomaly scores are extracted from the finetuned network via the scoring function\n",
    "\n",
    "\\begin{equation} \\tag{4}\n",
    "  S(x)=-\\max_k \\ell_k(x)\n",
    "\\end{equation}\n",
    "\n",
    "This anomaly scoring function is referred to as the *max logit scoring function*. The negative sign associates higher scores with more anomalous instances. \n",
    "\n",
    "During each round, finetuning will be done on the new data augmented with the training coreset.\n",
    "\n",
    "\n",
    "### The SAIL-ON Dataset\n",
    "The SAIL-ON Dataset is comprised of images and relevant metadata that specifies bounding boxes for the *subject*, *verb*, and *object* in each. Each image is not guaranteed to have a subject, verb, and object, however. For example, some images only contain an object and specify an object bounding box accordingly. As an example of a cropped and normalized image,\n",
    "\n",
    "| Category | Image | Label |\n",
    "| ----------- | --------- | ----------- |\n",
    "| Subject | <img src=\"subject_example_image.jpg\" alt=\"subject\" width=\"200\"/> | Person |\n",
    "| Verb | <img src=\"verb_example_image.jpg\" alt=\"verb\" width=\"200\"/> | Ride |\n",
    "| Object |<img src=\"object_example_image.jpg\" alt=\"object\" width=\"200\"/> | Bicycle |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "\n",
    "We start by setting up the data, importing relevant packages, and initializing our SVO dataset and dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from data.svodataset import SVODataset\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "def custom_collate(batch):\n",
    "    subject_images = []\n",
    "    verb_images = []\n",
    "    object_images = []\n",
    "    spatial_encodings = []\n",
    "    subject_labels = []\n",
    "    verb_labels = []\n",
    "    object_labels = []\n",
    "    for subject_image, verb_image, object_image, spatial_encoding, subject_label, verb_label, object_label in batch:\n",
    "        subject_images.append(subject_image)\n",
    "        verb_images.append(verb_image)\n",
    "        object_images.append(object_image)\n",
    "        spatial_encodings.append(spatial_encoding)\n",
    "        subject_labels.append(subject_label)\n",
    "        verb_labels.append(verb_label)\n",
    "        object_labels.append(object_label)\n",
    "\n",
    "    return subject_images, verb_images, object_images, spatial_encodings, subject_labels, verb_labels, object_labels\n",
    "\n",
    "train_dataset = SVODataset(\n",
    "    name = 'Custom',\n",
    "    data_root = 'Custom',\n",
    "    csv_path = 'Custom/annotations/dataset_v4_2_train.csv',\n",
    "    training = True\n",
    ")\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = 16,\n",
    "    shuffle = True,\n",
    "    collate_fn = custom_collate\n",
    ")\n",
    "\n",
    "test_dataset = SVODataset(\n",
    "    name = 'Custom',\n",
    "    data_root = 'Custom',\n",
    "    csv_path = 'Custom/annotations/dataset_v4_2_val.csv',\n",
    "    training = False\n",
    ")\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size = 16,\n",
    "    shuffle = True,\n",
    "    collate_fn = custom_collate\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we initialize our trained subject classifier and feature extractor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_dim = 256\n",
    "num_subject_classes = 5\n",
    "\n",
    "state_dicts = torch.load(f'new_subject_classifier.pth')\n",
    "\n",
    "feature_extractor = resnet18(pretrained=True)\n",
    "feature_extractor.fc = torch.nn.Linear(feature_extractor.fc.weight.shape[1], bottleneck_dim)\n",
    "subject_classifier = torch.nn.Linear(bottleneck_dim, num_subject_classes)\n",
    "\n",
    "feature_extractor.load_state_dict(state_dicts['feature_extractor'])\n",
    "subject_classifier.load_state_dict(state_dicts['classifier'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we want to run examples through our network to extract the latent subject representations, $\\mathbf{z}$. These can be used to run experiments on our margin loss classifier. *If these are already saved locally, then you don't need to run this again. Instead, move on to the next code block.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor.eval()\n",
    "subject_classifier.eval()\n",
    "def extract_nom_anom_datasets(dataloader, embeddings=False):\n",
    "    nom = None\n",
    "    nom_labels = None\n",
    "\n",
    "    anom = None\n",
    "    anom_labels  = None\n",
    "\n",
    "    iter_num = 0\n",
    "\n",
    "    for subject_images, verb_images, object_images, spatial_encodings, subject_labels, verb_labels, object_labels in dataloader:\n",
    "        for subject_image, verb_image, object_image, spatial_encoding, subject_label, verb_label, object_label in zip(subject_images, verb_images, object_images, spatial_encodings, subject_labels, verb_labels, object_labels):\n",
    "            if subject_image is not None:\n",
    "\n",
    "                if embeddings:\n",
    "                    subject = feature_extractor(torch.unsqueeze(subject_image,0))\n",
    "                else:\n",
    "                    subject = torch.unsqueeze(subject_image, 0)\n",
    "\n",
    "                # # Novel label is 0\n",
    "                if subject_label != 0:\n",
    "                    if nom is None:\n",
    "                        nom = subject\n",
    "                    else:\n",
    "                        nom = torch.vstack((nom, subject))\n",
    "\n",
    "                    if nom_labels is None:\n",
    "                        nom_labels = torch.unsqueeze(subject_label,0)\n",
    "                    else:\n",
    "                        nom_label_dim_last = nom_labels.shape[0]\n",
    "                        nom_labels = torch.vstack((nom_labels, torch.unsqueeze(subject_label,0)))\n",
    "                        nom_label_dim_now = nom_labels.shape[0]\n",
    "\n",
    "                        assert nom_labels.shape[0] == nom.shape[0], f\"X: {nom.shape} and y: {nom_labels.shape} mismatch, iter num is {iter_num}\"\n",
    "                        assert nom_label_dim_last == nom_label_dim_now-1, \"nom_label dimension changed\"\n",
    "\n",
    "                else:\n",
    "                    if anom is None:\n",
    "                        anom = subject\n",
    "                    else:\n",
    "                        anom = torch.vstack((anom, subject))\n",
    "\n",
    "                    if anom_labels is None:\n",
    "                        anom_labels = torch.unsqueeze(subject_label,0)\n",
    "                    else:\n",
    "                        anom_labels = torch.vstack((anom_labels, torch.unsqueeze(subject_label,0)))\n",
    "\n",
    "            iter_num += 1\n",
    "\n",
    "    subject_nom_dataset  = torch.utils.data.TensorDataset(nom,  nom_labels)\n",
    "    subject_anom_dataset = torch.utils.data.TensorDataset(anom, anom_labels)\n",
    "\n",
    "    return subject_nom_dataset, subject_anom_dataset\n",
    "\n",
    "train_nom_dataset, train_anom_dataset = extract_nom_anom_datasets(train_data_loader, embeddings=True)\n",
    "torch.save(train_nom_dataset, 's_z_train_nom_dataset.pt')\n",
    "torch.save(train_anom_dataset, 's_z_train_anom_dataset.pt')\n",
    "\n",
    "test_nom_dataset, test_anom_dataset = extract_nom_anom_datasets(test_data_loader, embeddings=True)\n",
    "torch.save(test_nom_dataset, 's_z_test_nom_dataset.pt')\n",
    "torch.save(test_anom_dataset, 's_z_test_anom_dataset.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coreset Computation (Bypass for now)\n",
    "\n",
    "The method used to compute our training coreset can be seen in the [paper](https://arxiv.org/pdf/2006.03875.pdf) by Borsos et al. or in the corresponding [git repo](https://github.com/zalanborsos/bilevel_coresets). In the following steps we draw heavily from the code found there.\n",
    "\n",
    "Our baseline with which we compare the coreset results is the case where we draw a uniform random sample from the training data of size $m$ and use that in lieu of our coreset. We start by implementing the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset \n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import torch.nn.functional as F\n",
    "\n",
    "subset_size = 50\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# choose random inds\n",
    "uniform_inds = np.random.choice(train_dataset.data.shape[0], subset_size, replace=False)\n",
    "uniform_subset = Subset(train_dataset, uniform_inds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Exposure Loss\n",
    "\n",
    "Here, we adopt a loss function that depends on an instances novelty or lack thereof. If a given instance is novel, we employ a uniform cross entropy loss over the known classes and use this as our gradient signal. Alternatively, if an instance is known, we use label imputation. This means that even though we have binary label 0, we use label smoothing.\n",
    "\n",
    "\\begin{equation} \\tag{5}\n",
    "  k^*=\\argmax_k \\ell(k)\n",
    "\\end{equation}\n",
    "\n",
    "where $\\ell(k)$ is the logit of class $k$. We then set the target value for class $k^*$ to be a smoothed label with some $\\alpha$ value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "train_nom_dataset  = torch.load('s_z_train_nom_dataset.pt')\n",
    "train_anom_dataset = torch.load('s_z_train_anom_dataset.pt')\n",
    "test_anom_dataset  = torch.load('s_z_test_anom_dataset.pt')\n",
    "test_nom_dataset   = torch.load('s_z_test_nom_dataset.pt')\n",
    "\n",
    "test_anom_dataloader   = \\\n",
    "        torch.utils.data.DataLoader(\n",
    "            test_anom_dataset,\n",
    "            batch_size = 8,\n",
    "            shuffle = True,\n",
    "            num_workers = 0\n",
    "        )\n",
    "\n",
    "test_nom_dataloader   = \\\n",
    "        torch.utils.data.DataLoader(\n",
    "            test_nom_dataset,\n",
    "            batch_size = 8,\n",
    "            shuffle = True,\n",
    "            num_workers = 0\n",
    "        )\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "subject_classifier.to(device)\n",
    "subject_classifier.eval()\n",
    "with torch.no_grad():\n",
    "    m = nn.Softmax(dim=1)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (X, y) in enumerate(test_nom_dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_pred = m(subject_classifier(X))\n",
    "        y_pred = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "        correct += torch.sum(torch.squeeze(y)==y_pred)\n",
    "        total += X.shape[0]\n",
    "\n",
    "    accuracy = correct/total\n",
    "    print(f\"Number correct: {correct}\")\n",
    "    print(f\"accuracy is {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(0)\n",
    "cudnn.deterministic = True\n",
    "cudnn.benchmark = True\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "alphas = [0.01, 0.03, 0.1, 0.3]\n",
    "learning_rates = [3e-4, 1e-3, 3e-3, 1e-2, 3e-2]\n",
    "learning_rate = 1e-3\n",
    "alpha = 0.01\n",
    "lambda_l2 = 1e-5\n",
    "batch_size = 8\n",
    "\n",
    "num_known_classes = 4\n",
    "\n",
    "train_nom_dataset  = torch.load('s_z_train_nom_dataset.pt')\n",
    "train_anom_dataset = torch.load('s_z_train_anom_dataset.pt')\n",
    "test_anom_dataset  = torch.load('s_z_test_anom_dataset.pt')\n",
    "test_nom_dataset   = torch.load('s_z_test_nom_dataset.pt')\n",
    "\n",
    "train_anom_dataloader = \\\n",
    "        torch.utils.data.DataLoader(\n",
    "            train_anom_dataset,\n",
    "            batch_size = batch_size,\n",
    "            shuffle = True,\n",
    "            num_workers = 0\n",
    "        )\n",
    "test_nom_dataloader   = \\\n",
    "        torch.utils.data.DataLoader(\n",
    "            test_nom_dataset,\n",
    "            batch_size = batch_size,\n",
    "            shuffle = True,\n",
    "            num_workers = 0\n",
    "        )\n",
    "\n",
    "novel_loss = nn.CrossEntropyLoss()\n",
    "#known_loss = nn.CrossEntropyLoss(label_smoothing=alpha)\n",
    "\n",
    "optimizer = torch.optim.SGD(subject_classifier.parameters(), lr=learning_rate, weight_decay=lambda_l2)\n",
    "\n",
    "m = torch.nn.Softmax(dim=1)\n",
    "one_hot = torch.nn.functional.one_hot\n",
    "\n",
    "subject_classifier.train()\n",
    "subject_classifier.to(device)\n",
    "\n",
    "# Since there are only 73 examples in train_anom, this should only utilize\n",
    "# 73 of the known in instances in the test set, leaving the rest for testing.\n",
    "# There are 721 nominal examples in the test nom set total.\n",
    "\n",
    "losses = []\n",
    "lr_losses = []\n",
    "alpha_losses = []\n",
    "num_batches = len(train_anom_dataset) // batch_size\n",
    "\n",
    "for alpha in [0.01]:\n",
    "    #optimizer = torch.optim.SGD(subject_classifier.parameters(), lr=lr, weight_decay=lambda_l2)\n",
    "    known_loss = nn.CrossEntropyLoss(label_smoothing=alpha)\n",
    "    losses = []\n",
    "    for i in range(1):\n",
    "        for j, ((anom_X, anom_y), (nom_X, nom_y)) in tqdm(enumerate(zip(train_anom_dataloader, test_nom_dataloader))):\n",
    "\n",
    "            anom_X = anom_X.to(device)\n",
    "            nom_X  = nom_X.to(device)\n",
    "\n",
    "            # Keep this line uncommented for detection feedback\n",
    "            nom_y = torch.zeros_like(nom_y)\n",
    "\n",
    "            # Feed forward\n",
    "            anom_predictions = m(subject_classifier(anom_X)[:,1:5])\n",
    "            nom_predictions  = m(subject_classifier(nom_X)[:,1:5])\n",
    "            \n",
    "            # Keep this line uncommented for detection feedback\n",
    "            nom_y_orig = nom_y\n",
    "            nom_y = torch.argmax(nom_predictions, dim=1)+1 #[:,1:5]\n",
    "\n",
    "            # If the instance is anomalous, use uniform labeling\n",
    "            # NOTE: label matrix is (batch_size x num_nominal_classes)\n",
    "            anom_y = (1/num_known_classes)*torch.ones((len(anom_y),num_known_classes))\n",
    "\n",
    "            # Converting the nominal labels to be one-hot. Note that these\n",
    "            # will be label-smoothed when loss is computed\n",
    "            nom_y = torch.squeeze(one_hot(nom_y-1, num_known_classes).float()) #nom_y = torch.argmax(nom_predictions, dim=1)+1 #[:,1:5]\n",
    "\n",
    "            anom_y = anom_y.to(device)\n",
    "            nom_y = nom_y.to(device)\n",
    "\n",
    "            # Compute loss. Note that arguments are (input, target).\n",
    "            #\n",
    "            # Input needs to be (batch_size x num_classes).\n",
    "            # Target needs to be same shape as input since it contains class\n",
    "            # probabilities.\n",
    "            loss = novel_loss(anom_predictions, anom_y) + known_loss(nom_predictions, nom_y)\n",
    "            losses.append(loss)\n",
    "\n",
    "            # Zero the optimizer's gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Backpropagate to compute the gradients\n",
    "            # of the loss with respect to our learnable\n",
    "            # parameters\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the learnable parameters\n",
    "            optimizer.step()\n",
    "    \n",
    "    alpha_losses.append(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "batches = np.arange(0,len(losses))\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(8,6))\n",
    "\n",
    "fig.suptitle('Alpha Sweep', fontsize=15)\n",
    "\n",
    "for i, alpha in enumerate(alphas):\n",
    "    ax.plot(batches, alpha_losses[i], label=f'alpha={alpha}')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Batch Number (16 instances/batch)')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(batches, losses)\n",
    "# plt.title('Batch Training: Log Loss')\n",
    "# plt.xlabel('Batch Number (16 instances/batch)')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_anom_dataloader   = \\\n",
    "        torch.utils.data.DataLoader(\n",
    "            test_anom_dataset,\n",
    "            batch_size = 8,\n",
    "            shuffle = True,\n",
    "            num_workers = 0\n",
    "        )\n",
    "\n",
    "subject_classifier.eval()\n",
    "with torch.no_grad():\n",
    "    m = nn.Softmax(dim=1)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (X, y) in enumerate(test_nom_dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_pred = m(subject_classifier(X))\n",
    "        y_pred = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "        correct += torch.sum(torch.squeeze(y)==y_pred)\n",
    "        total += X.shape[0]\n",
    "\n",
    "    accuracy = correct/total\n",
    "    print(f\"Number correct: {correct}\")\n",
    "    print(f\"accuracy is {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (X, y) in enumerate(test_anom_dataloader):\n",
    "        y = torch.zeros_like(y)\n",
    "        #y = torch.ones_like(y)\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_pred = subject_classifier(X)\n",
    "        y_pred, _ = torch.max(y_pred, dim=1)\n",
    "        y_pred *= -1\n",
    "       \n",
    "        y_pred = torch.where(y_pred>-3, 1, 0)\n",
    "\n",
    "        print(y_pred)\n",
    "        print(y)\n",
    "\n",
    "        correct += torch.sum(torch.squeeze(y)==y_pred)\n",
    "        total += X.shape[0]\n",
    "\n",
    "    accuracy = correct/total\n",
    "    print(f\"Number correct: {correct}\")\n",
    "    print(f\"accuracy is {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using 2-fold cross validation for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        m.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(0)\n",
    "cudnn.deterministic = True\n",
    "cudnn.benchmark = True\n",
    "\n",
    "dset1 = train_anom_dataset\n",
    "dset2X, dset2y = test_nom_dataset[0:len(dset1)]\n",
    "dset2 = torch.utils.data.TensorDataset(dset2X, dset2y)\n",
    "\n",
    "dset = torch.utils.data.ConcatDataset([dset1, dset2])\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 16\n",
    "k = 2\n",
    "splits = KFold(n_splits=k, shuffle=True, random_state=0)\n",
    "fold_performance = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_oe_epoch(model,device,dataloader,known_loss_fn,novel_loss_fn,optimizer):\n",
    "    train_loss,train_correct=0.0,0\n",
    "    model.train()\n",
    "    for images, labels in dataloader:\n",
    "\n",
    "        images,labels = images.to(device),labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "\n",
    "        print(labels)\n",
    "\n",
    "        kn_idxs  = [i for i in labels if i != 0]\n",
    "        nov_idxs = [i for i in labels if i == 0]\n",
    "        kn_output, kn_labels   = images[kn_idxs],  labels[kn_idxs]\n",
    "        nov_output, nov_labels = images[nov_idxs], labels[nov_idxs]\n",
    "\n",
    "        print(kn_labels)\n",
    "        print(nov_labels)\n",
    "\n",
    "        loss = known_loss_fn(kn_output,kn_labels) + novel_loss_fn(nov_output,nov_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        scores, predictions = torch.max(output.data, 1)\n",
    "        train_correct += (predictions == labels).sum().item()\n",
    "\n",
    "    return train_loss,train_correct\n",
    "\n",
    "def valid_epoch(model,device,dataloader,loss_fn):\n",
    "    valid_loss, val_correct = 0.0, 0\n",
    "    model.eval()\n",
    "    for images, labels in dataloader:\n",
    "\n",
    "        images,labels = images.to(device),labels.to(device)\n",
    "        output = model(images)\n",
    "        loss=loss_fn(output,labels)\n",
    "        valid_loss+=loss.item()*images.size(0)\n",
    "        scores, predictions = torch.max(output.data,1)\n",
    "        val_correct+=(predictions == labels).sum().item()\n",
    "\n",
    "    return valid_loss,val_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(dset)))):\n",
    "\n",
    "    print('Fold {}'.format(fold + 1))\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(val_idx)\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "    test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model = ConvNet()\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.002)\n",
    "\n",
    "    history = {'train_loss': [], 'test_loss': [],'train_acc':[],'test_acc':[]}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_correct=train_epoch(model,device,train_loader,criterion,optimizer)\n",
    "        test_loss, test_correct=valid_epoch(model,device,test_loader,criterion)\n",
    "\n",
    "        train_loss = train_loss / len(train_loader.sampler)\n",
    "        train_acc = train_correct / len(train_loader.sampler) * 100\n",
    "        test_loss = test_loss / len(test_loader.sampler)\n",
    "        test_acc = test_correct / len(test_loader.sampler) * 100\n",
    "\n",
    "        print(\"Epoch:{}/{} AVG Training Loss:{:.3f} AVG Test Loss:{:.3f} AVG Training Acc {:.2f} % AVG Test Acc {:.2f} %\".format(epoch + 1,\n",
    "                                                                                                             num_epochs,\n",
    "                                                                                                             train_loss,\n",
    "                                                                                                             test_loss,\n",
    "                                                                                                             train_acc,\n",
    "                                                                                                             test_acc))\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['test_loss'].append(test_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['test_acc'].append(test_acc)\n",
    "\n",
    "    foldperf['fold{}'.format(fold+1)] = history  \n",
    "\n",
    "torch.save(model,'k_cross_CNN.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a sanity check, see how it performs on known examples in test set.\n",
    "# Alex said that it should be ~95% accurate\n",
    "dset = torch.load('s_X_test_nom_dataset.pt')\n",
    "dl = torch.utils.data.DataLoader(dset, batch_size=8, shuffle=True, num_workers=0)\n",
    "with torch.no_grad():\n",
    "    m = nn.Softmax(dim=1)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (X, y) in enumerate(dl):\n",
    "        # print(y)\n",
    "        y_pred = feature_extractor(X)\n",
    "        y_pred = m(subject_classifier(y_pred))\n",
    "        # print(y_pred)\n",
    "        y_pred = torch.argmax(y_pred, dim=1)\n",
    "        # print(y_pred)\n",
    "\n",
    "        correct += torch.sum(torch.squeeze(y)==y_pred)\n",
    "        total += X.shape[0]\n",
    "        #print(f\"correct: {correct}\\ntotal: {total}\")\n",
    "\n",
    "    accuracy = correct/total\n",
    "    print(f\"Number correct: {correct}\")\n",
    "    print(f\"accuracy is {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a simple experiment, we want to compare these results with margin loss results from previous experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomalyMarginLoss(outputs, labels, tau=0.5, mu=0.2):\n",
    "    ''' \n",
    "    Score A(x_q) = -max_k \\sum_{j=1}^d w_{kj} z_{qj} \n",
    "    \n",
    "    k: class\n",
    "    q: query number\n",
    "    j: feature number\n",
    "    \n",
    "    L(W) = max(0, [A(x_i) - (\\tao + \\mu n_i)(-n_i)])\n",
    "\n",
    "    where n_i is the label corresponding to example i:\n",
    "\n",
    "    +1: novel\n",
    "    -1: nominal\n",
    "    \n",
    "    Args:\n",
    "        outputs: A(x_i)\n",
    "        labels:  n_i\n",
    "    '''\n",
    "    adjusted = (outputs-(tau+mu*labels))*(-labels)\n",
    "    instancewise_loss =  torch.maximum(torch.zeros_like(adjusted),adjusted)\n",
    "    return torch.sum(instancewise_loss)\n",
    "\n",
    "\n",
    "class AnomalyFC(nn.Module):\n",
    "    ''' This will be a single fc layer with no activation '''\n",
    "    def __init__(self, D_in, D_out):\n",
    "        super(AnomalyFC, self).__init__()\n",
    "        self.linear = nn.Linear(D_in, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Computing the logits\n",
    "        x = self.linear(x)\n",
    "\n",
    "        # And, finally, an anomaly score\n",
    "        x = -(torch.max(x,1)[0])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline with Outlier Exposure\n",
    "\n",
    "Training a 4-class Resnet-18 on the union of the OSU known training data and the OSU Feedback Dataset using outlier exposure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prep the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "num_known_classes = 4\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_nom_dataset  = torch.load('s_X_train_nom_dataset.pt')\n",
    "train_anom_dataset = torch.load('s_X_train_anom_dataset.pt')\n",
    "test_anom_dataset  = torch.load('s_X_test_anom_dataset.pt')\n",
    "test_nom_dataset   = torch.load('s_X_test_nom_dataset.pt')\n",
    "\n",
    "dset1X, dset1y = train_anom_dataset[0:]\n",
    "dset1 = torch.utils.data.TensorDataset(dset1X, torch.hstack((dset1y, torch.zeros_like(dset1y))))\n",
    "dset2X, dset2y = test_nom_dataset[0:len(dset1)]\n",
    "dset2 = torch.utils.data.TensorDataset(dset2X, torch.hstack((dset2y, torch.zeros_like(dset2y))))\n",
    "dset3X, dset3y = train_nom_dataset[0:]\n",
    "dset3 = torch.utils.data.TensorDataset(dset3X, torch.hstack((dset3y, torch.ones_like(dset3y))))\n",
    "\n",
    "dset = torch.utils.data.ConcatDataset([dset1, dset2, dset3])\n",
    "\n",
    "dset_test1X, dset_test1y = test_nom_dataset[len(dset1):]\n",
    "dset_test1 = torch.utils.data.TensorDataset(dset_test1X, dset_test1y)\n",
    "dset_test2 = test_anom_dataset\n",
    "\n",
    "dset_test = torch.utils.data.ConcatDataset([dset_test1, dset_test2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/tom/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "# Transfer learning\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "\n",
    "# Freeze the backbone weights\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, num_known_classes)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "m = torch.nn.Softmax(dim=1)\n",
    "one_hot = torch.nn.functional.one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the hyperparameters. We'll use k-fold for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=0.1\n",
    "num_epochs = 100\n",
    "k = 4\n",
    "splits = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "fold_perf = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detection Feedback Helper Functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def train_detection_epoch_orig(model,device,dataloader,trainex_loss,novel_loss,known_loss,optimizer):\n",
    "    tau = -3\n",
    "    train_loss,train_correct=0.0,0\n",
    "    model.train()\n",
    "\n",
    "    nscores = []\n",
    "    ascores = []\n",
    "    tscores = []\n",
    "\n",
    "    for images, labels_tensor in dataloader:\n",
    "\n",
    "        train_known_label_flags = labels_tensor[:,1]\n",
    "        labels = labels_tensor[:,0]\n",
    "\n",
    "        # To convert to detection setup\n",
    "        train_mask = train_known_label_flags > 0\n",
    "        feedback_novel_mask = (train_known_label_flags == 0) & (labels == 0)\n",
    "        feedback_nomin_mask = (train_known_label_flags == 0) & (labels != 0)\n",
    "\n",
    "        # print(f'feedback_novel_mask: {feedback_novel_mask}')\n",
    "        # print(f'feedback_nomin_mask: {feedback_nomin_mask}')\n",
    "\n",
    "        train_X = images[torch.squeeze(train_mask),:]\n",
    "        train_y = labels[train_mask]\n",
    "        \n",
    "        # print(f'feedback_novel_mask shape: {feedback_novel_mask.shape}')\n",
    "        feedback_nov_X = images[torch.squeeze(feedback_novel_mask),:]\n",
    "        feedback_nov_y = labels[feedback_novel_mask]\n",
    "\n",
    "        # print(f'feedback_nomin_mask shape: {feedback_nomin_mask.shape}')\n",
    "        feedback_nom_X = images[torch.squeeze(feedback_nomin_mask),:]\n",
    "        feedback_nom_y = labels[feedback_nomin_mask]\n",
    "\n",
    "        # print(f'train_y shape: {train_y.shape}')\n",
    "        # print(f'feedback_nov_y shape: {feedback_nov_y.shape}')\n",
    "        # print(f'feedback_nom_y shape: {feedback_nom_y.shape}')\n",
    "\n",
    "        if feedback_nov_X.shape[0] != 0:\n",
    "            feedback_nov_X = feedback_nov_X.to(device)\n",
    "            novel_logits = model(feedback_nov_X)\n",
    "            novel_output = novel_logits #m(novel_logits)\n",
    "            # If the instance is anomalous, use uniform labeling\n",
    "            # NOTE: label matrix is (batch_size x num_nominal_classes)\n",
    "            feedback_nov_y = (1/num_known_classes)*torch.ones((feedback_nov_y.shape[0],num_known_classes))\n",
    "\n",
    "        if feedback_nom_X.shape[0] != 0:\n",
    "            feedback_nom_X = feedback_nom_X.to(device)\n",
    "            nom_logits = model(feedback_nom_X)\n",
    "            nom_output = nom_logits #m(nom_logits)\n",
    "            feedback_nom_y = torch.argmax(nom_output, dim=1)\n",
    "            #feedback_nom_y = torch.squeeze(one_hot(feedback_nom_y, num_known_classes).float())\n",
    "\n",
    "        if train_X.shape[0] != 0:\n",
    "            train_X = train_X.to(device)\n",
    "            train_logits = model(train_X)\n",
    "            train_output = train_logits #m(train_logits)\n",
    "\n",
    "        train_y = torch.squeeze(one_hot(train_y-1, num_known_classes).float())\n",
    "\n",
    "        # Compute the loss\n",
    "        if feedback_nov_X.shape[0] != 0 and feedback_nom_X.shape[0] != 0 and train_X.shape[0] != 0:\n",
    "            feedback_nov_y = feedback_nov_y.to(device)\n",
    "            feedback_nom_y = feedback_nom_y.to(device)\n",
    "            train_y = train_y.to(device)\n",
    "            # print(f'train_output shape: {train_output.shape}')\n",
    "            # print(f'train_y shape: {train_y.shape}')\n",
    "            # print(f'novel_output shape: {novel_output.shape}')\n",
    "            # print(f'feedback_nov_y shape: {feedback_nov_y.shape}')\n",
    "            # print(f'nom_output shape: {nom_output.shape}')\n",
    "            # print(f'feedback_nom_y shape: {feedback_nom_y.shape}')\n",
    "            # # print(f'nom output: {nom_output}')\n",
    "            # # print(f'nominal labels: {feedback_nom_y}')\n",
    "            # print(f'novel outputs: {novel_output}')\n",
    "            # print(f'novel labels: {feedback_nov_y}')\n",
    "            # print(f'nom output: {nom_output}')\n",
    "            # print(f'nom labels: {feedback_nom_y}')\n",
    "            # print(f'train output: {train_output}')\n",
    "            # print(f'train labels: {train_y}')\n",
    "            loss = trainex_loss(train_output, train_y) \\\n",
    "                     + known_loss(nom_output, feedback_nom_y) \\\n",
    "                     + novel_loss(novel_output, feedback_nov_y)\n",
    "        elif feedback_nom_X.shape[0] != 0 and train_X.shape[0] != 0:\n",
    "            feedback_nom_y = feedback_nom_y.to(device)\n",
    "            train_y = train_y.to(device)\n",
    "            loss = trainex_loss(train_output, train_y) \\\n",
    "                    + known_loss(nom_output, feedback_nom_y)\n",
    "        elif feedback_nov_X.shape[0] != 0 and train_X.shape[0] != 0:\n",
    "            feedback_nov_y = feedback_nov_y.to(device)\n",
    "            train_y = train_y.to(device)\n",
    "            loss = trainex_loss(train_output, train_y) \\\n",
    "                    + novel_loss(novel_output, feedback_nov_y)\n",
    "        elif feedback_nov_X.shape[0] != 0 and feedback_nom_X.shape[0] != 0:\n",
    "            feedback_nov_y = feedback_nov_y.to(device)\n",
    "            feedback_nom_y = feedback_nom_y.to(device)\n",
    "            loss = known_loss(nom_output, feedback_nom_y) \\\n",
    "                    + novel_loss(novel_output, feedback_nov_y)\n",
    "        elif train_X.shape[0] != 0:\n",
    "            train_y = train_y.to(device)\n",
    "            loss = trainex_loss(train_output, train_y)\n",
    "        elif feedback_nom_X.shape[0] != 0:\n",
    "            feedback_nom_y = feedback_nom_y.to(device)\n",
    "            loss = known_loss(nom_output, feedback_nom_y)\n",
    "        elif feedback_nov_X.shape[0] != 0:\n",
    "            feedback_nov_y = feedback_nov_y.to(device)\n",
    "            loss = novel_loss(novel_output, feedback_nov_y)\n",
    "\n",
    "\n",
    "        loss /= images.shape[0]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "\n",
    "        if feedback_nov_X.shape[0] != 0:\n",
    "            novel_scores, novel_predictions = torch.max(novel_logits.data, 1)\n",
    "            novel_scores *= -1\n",
    "\n",
    "        if feedback_nom_X.shape[0] != 0:\n",
    "            nom_scores, nom_predictions = torch.max(nom_logits.data, 1)\n",
    "            nom_scores *= -1\n",
    "\n",
    "        if train_X.shape[0] != 0:\n",
    "            train_scores, nom_predictions = torch.max(train_logits.data, 1)\n",
    "            train_scores *= -1\n",
    "\n",
    "\n",
    "        if feedback_nov_X.shape[0] != 0:\n",
    "            ascores = ascores + [i for i in novel_scores]\n",
    "        if feedback_nom_X.shape[0] != 0:\n",
    "            nscores = nscores + [i for i in nom_scores]\n",
    "        if train_X.shape[0] != 0:\n",
    "            tscores = tscores + [i for i in train_scores]\n",
    "\n",
    "    ascores = torch.tensor(ascores)\n",
    "    nscores = torch.tensor(nscores)\n",
    "    tscores = torch.tensor(tscores)\n",
    "    y_true  = torch.hstack((torch.ones_like(ascores), torch.zeros_like(nscores), torch.zeros_like(tscores)))\n",
    "    y_score = torch.hstack((ascores, nscores, tscores))\n",
    "    train_auc = roc_auc_score(y_true, y_score)\n",
    "\n",
    "    return train_loss,None,train_auc\n",
    "\n",
    "# TODO: Fix the detection by using logits to compute scores instead of softmaxed logits\n",
    "def valid_detection_epoch_orig(model,device,dataloader,trainex_loss,novel_loss,known_loss):\n",
    "    tau = -3\n",
    "    val_loss,val_correct=0.0,0\n",
    "    model.eval()\n",
    "\n",
    "    nscores = []\n",
    "    ascores = []\n",
    "    tscores = []\n",
    "\n",
    "    for images, labels_tensor in dataloader:\n",
    "\n",
    "        train_known_label_flags = labels_tensor[:,1]\n",
    "        labels = labels_tensor[:,0]\n",
    "\n",
    "        # To convert to detection setup\n",
    "        train_mask = train_known_label_flags > 0\n",
    "        feedback_novel_mask = (train_known_label_flags == 0) & (labels == 0)\n",
    "        feedback_nomin_mask = (train_known_label_flags == 0) & (labels != 0)\n",
    "\n",
    "        # print(f'feedback_novel_mask: {feedback_novel_mask}')\n",
    "        # print(f'feedback_nomin_mask: {feedback_nomin_mask}')\n",
    "\n",
    "        train_X = images[torch.squeeze(train_mask),:]\n",
    "        train_y = labels[train_mask]\n",
    "        \n",
    "        # print(f'feedback_novel_mask shape: {feedback_novel_mask.shape}')\n",
    "        feedback_nov_X = images[torch.squeeze(feedback_novel_mask),:]\n",
    "        feedback_nov_y = labels[feedback_novel_mask]\n",
    "\n",
    "        # print(f'feedback_nomin_mask shape: {feedback_nomin_mask.shape}')\n",
    "        feedback_nom_X = images[torch.squeeze(feedback_nomin_mask),:]\n",
    "        feedback_nom_y = labels[feedback_nomin_mask]\n",
    "\n",
    "        # print(f'train_y shape: {train_y.shape}')\n",
    "        # print(f'feedback_nov_y shape: {feedback_nov_y.shape}')\n",
    "        # print(f'feedback_nom_y shape: {feedback_nom_y.shape}')\n",
    "\n",
    "        if feedback_nov_X.shape[0] != 0:\n",
    "            feedback_nov_X = feedback_nov_X.to(device)\n",
    "            novel_logits = model(feedback_nov_X)\n",
    "            novel_output = novel_logits #m(novel_logits)\n",
    "            # If the instance is anomalous, use uniform labeling\n",
    "            # NOTE: label matrix is (batch_size x num_nominal_classes)\n",
    "            feedback_nov_y = (1/num_known_classes)*torch.ones((feedback_nov_y.shape[0],num_known_classes))\n",
    "\n",
    "        if feedback_nom_X.shape[0] != 0:\n",
    "            feedback_nom_X = feedback_nom_X.to(device)\n",
    "            nom_logits = model(feedback_nom_X)\n",
    "            nom_output = nom_logits #m(nom_logits)\n",
    "            feedback_nom_y = torch.argmax(nom_output, dim=1)\n",
    "            #feedback_nom_y = torch.squeeze(one_hot(feedback_nom_y, num_known_classes).float())\n",
    "\n",
    "        if train_X.shape[0] != 0:\n",
    "            train_X = train_X.to(device)\n",
    "            train_logits = model(train_X)\n",
    "            train_output = train_logits #m(train_logits)\n",
    "\n",
    "        train_y = torch.squeeze(one_hot(train_y-1, num_known_classes).float())\n",
    "\n",
    "        # Compute the loss\n",
    "        if feedback_nov_X.shape[0] != 0 and feedback_nom_X.shape[0] != 0 and train_X.shape[0] != 0:\n",
    "            feedback_nov_y = feedback_nov_y.to(device)\n",
    "            feedback_nom_y = feedback_nom_y.to(device)\n",
    "            train_y = train_y.to(device)\n",
    "            loss = trainex_loss(train_output, train_y) \\\n",
    "                     + known_loss(nom_output, feedback_nom_y) \\\n",
    "                     + novel_loss(novel_output, feedback_nov_y)\n",
    "        elif feedback_nom_X.shape[0] != 0 and train_X.shape[0] != 0:\n",
    "            feedback_nom_y = feedback_nom_y.to(device)\n",
    "            train_y = train_y.to(device)\n",
    "            loss = trainex_loss(train_output, train_y) \\\n",
    "                    + known_loss(nom_output, feedback_nom_y)\n",
    "        elif feedback_nov_X.shape[0] != 0 and train_X.shape[0] != 0:\n",
    "            feedback_nov_y = feedback_nov_y.to(device)\n",
    "            train_y = train_y.to(device)\n",
    "            loss = trainex_loss(train_output, train_y) \\\n",
    "                    + novel_loss(novel_output, feedback_nov_y)\n",
    "        elif feedback_nov_X.shape[0] != 0 and feedback_nom_X.shape[0] != 0:\n",
    "            feedback_nov_y = feedback_nov_y.to(device)\n",
    "            feedback_nom_y = feedback_nom_y.to(device)\n",
    "            loss = known_loss(nom_output, feedback_nom_y) \\\n",
    "                    + novel_loss(novel_output, feedback_nov_y)\n",
    "        elif train_X.shape[0] != 0:\n",
    "            train_y = train_y.to(device)\n",
    "            loss = trainex_loss(train_output, train_y)\n",
    "        elif feedback_nom_X.shape[0] != 0:\n",
    "            feedback_nom_y = feedback_nom_y.to(device)\n",
    "            loss = known_loss(nom_output, feedback_nom_y)\n",
    "        elif feedback_nov_X.shape[0] != 0:\n",
    "            feedback_nov_y = feedback_nov_y.to(device)\n",
    "            loss = novel_loss(novel_output, feedback_nov_y)\n",
    "\n",
    "        loss /= images.shape[0]\n",
    "        val_loss += loss.item() * images.size(0)\n",
    "\n",
    "        if feedback_nov_X.shape[0] != 0:\n",
    "            novel_scores, novel_predictions = torch.max(novel_logits.data, 1)\n",
    "            novel_scores *= -1\n",
    "\n",
    "        if feedback_nom_X.shape[0] != 0:\n",
    "            nom_scores, nom_predictions = torch.max(nom_logits.data, 1)\n",
    "            nom_scores *= -1\n",
    "\n",
    "        if train_X.shape[0] != 0:\n",
    "            train_scores, nom_predictions = torch.max(train_logits.data, 1)\n",
    "            train_scores *= -1\n",
    "\n",
    "        if feedback_nov_X.shape[0] != 0:\n",
    "            ascores = ascores + [i for i in novel_scores]\n",
    "        if feedback_nom_X.shape[0] != 0:\n",
    "            nscores = nscores + [i for i in nom_scores]\n",
    "        if train_X.shape[0] != 0:\n",
    "            tscores = tscores + [i for i in train_scores]\n",
    "\n",
    "    ascores = torch.tensor(ascores)\n",
    "    nscores = torch.tensor(nscores)\n",
    "    tscores = torch.tensor(tscores)\n",
    "    y_true  = torch.hstack((torch.ones_like(ascores), torch.zeros_like(nscores), torch.zeros_like(tscores)))\n",
    "    y_score = torch.hstack((ascores, nscores, tscores))\n",
    "    val_auc = roc_auc_score(y_true, y_score)\n",
    "\n",
    "    return val_loss,None,val_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a copy for running experiment 1.1.b.i.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def train_detection_epoch(model,device,dataloader,trainex_loss,novel_loss,known_loss,optimizer):\n",
    "    tau = -3\n",
    "    train_loss,train_correct=0.0,0\n",
    "    model.train()\n",
    "\n",
    "    nscores = []\n",
    "    ascores = []\n",
    "    tscores = []\n",
    "\n",
    "    for images, labels_tensor in dataloader:\n",
    "\n",
    "        train_known_label_flags = labels_tensor[:,1]\n",
    "        labels = labels_tensor[:,0]\n",
    "\n",
    "        # To convert to detection setup\n",
    "        train_mask = (train_known_label_flags > 0) | ((train_known_label_flags == 0) & (labels != 0))\n",
    "        feedback_novel_mask = (train_known_label_flags == 0) & (labels == 0)\n",
    "        feedback_nomin_mask = torch.tensor([False for i in range(labels.shape[0])]) #(train_known_label_flags == 0) & (labels != 0)\n",
    "\n",
    "        # print(f'feedback_novel_mask: {feedback_novel_mask}')\n",
    "        # print(f'feedback_nomin_mask: {feedback_nomin_mask}')\n",
    "\n",
    "        train_X = images[torch.squeeze(train_mask),:]\n",
    "        train_y = labels[train_mask]\n",
    "        \n",
    "        # print(f'feedback_novel_mask shape: {feedback_novel_mask.shape}')\n",
    "        feedback_nov_X = images[torch.squeeze(feedback_novel_mask),:]\n",
    "        feedback_nov_y = labels[feedback_novel_mask]\n",
    "\n",
    "        # print(f'feedback_nomin_mask shape: {feedback_nomin_mask.shape}')\n",
    "        feedback_nom_X = images[torch.squeeze(feedback_nomin_mask),:]\n",
    "        feedback_nom_y = labels[feedback_nomin_mask]\n",
    "\n",
    "        # print(f'train_y shape: {train_y.shape}')\n",
    "        # print(f'feedback_nov_y shape: {feedback_nov_y.shape}')\n",
    "        # print(f'feedback_nom_y shape: {feedback_nom_y.shape}')\n",
    "\n",
    "        if feedback_nov_X.shape[0] != 0:\n",
    "            feedback_nov_X = feedback_nov_X.to(device)\n",
    "            novel_logits = model(feedback_nov_X)\n",
    "            novel_output = novel_logits #m(novel_logits)\n",
    "            # If the instance is anomalous, use uniform labeling\n",
    "            # NOTE: label matrix is (batch_size x num_nominal_classes)\n",
    "            feedback_nov_y = (1/num_known_classes)*torch.ones((feedback_nov_y.shape[0],num_known_classes))\n",
    "\n",
    "        if feedback_nom_X.shape[0] != 0:\n",
    "            feedback_nom_X = feedback_nom_X.to(device)\n",
    "            nom_logits = model(feedback_nom_X)\n",
    "            nom_output = nom_logits #m(nom_logits)\n",
    "            feedback_nom_y = torch.argmax(nom_output, dim=1)\n",
    "            #feedback_nom_y = torch.squeeze(one_hot(feedback_nom_y, num_known_classes).float())\n",
    "\n",
    "        if train_X.shape[0] != 0:\n",
    "            train_X = train_X.to(device)\n",
    "            train_logits = model(train_X)\n",
    "            train_output = train_logits #m(train_logits)\n",
    "\n",
    "        train_y = torch.squeeze(one_hot(train_y-1, num_known_classes).float())\n",
    "\n",
    "        # Compute the loss\n",
    "        if feedback_nov_X.shape[0] != 0 and feedback_nom_X.shape[0] != 0 and train_X.shape[0] != 0:\n",
    "            feedback_nov_y = feedback_nov_y.to(device)\n",
    "            feedback_nom_y = feedback_nom_y.to(device)\n",
    "            train_y = train_y.to(device)\n",
    "            # print(f'train_output shape: {train_output.shape}')\n",
    "            # print(f'train_y shape: {train_y.shape}')\n",
    "            # print(f'novel_output shape: {novel_output.shape}')\n",
    "            # print(f'feedback_nov_y shape: {feedback_nov_y.shape}')\n",
    "            # print(f'nom_output shape: {nom_output.shape}')\n",
    "            # print(f'feedback_nom_y shape: {feedback_nom_y.shape}')\n",
    "            # # print(f'nom output: {nom_output}')\n",
    "            # # print(f'nominal labels: {feedback_nom_y}')\n",
    "            # print(f'novel outputs: {novel_output}')\n",
    "            # print(f'novel labels: {feedback_nov_y}')\n",
    "            # print(f'nom output: {nom_output}')\n",
    "            # print(f'nom labels: {feedback_nom_y}')\n",
    "            # print(f'train output: {train_output}')\n",
    "            # print(f'train labels: {train_y}')\n",
    "            loss = trainex_loss(train_output, train_y) \\\n",
    "                    + known_loss(nom_output, feedback_nom_y)\n",
    "                    #+ novel_loss(novel_output, feedback_nov_y) \\\n",
    "        elif feedback_nom_X.shape[0] != 0 and train_X.shape[0] != 0:\n",
    "            feedback_nom_y = feedback_nom_y.to(device)\n",
    "            train_y = train_y.to(device)\n",
    "            loss = trainex_loss(train_output, train_y) \\\n",
    "                    + known_loss(nom_output, feedback_nom_y)\n",
    "        elif feedback_nov_X.shape[0] != 0 and train_X.shape[0] != 0:\n",
    "            feedback_nov_y = feedback_nov_y.to(device)\n",
    "            train_y = train_y.to(device)\n",
    "            loss = trainex_loss(train_output, train_y) #\\\n",
    "                    #+ novel_loss(novel_output, feedback_nov_y)\n",
    "        elif feedback_nov_X.shape[0] != 0 and feedback_nom_X.shape[0] != 0:\n",
    "            feedback_nov_y = feedback_nov_y.to(device)\n",
    "            feedback_nom_y = feedback_nom_y.to(device)\n",
    "            loss = known_loss(nom_output, feedback_nom_y) #\\\n",
    "                    #novel_loss(novel_output, feedback_nov_y)\n",
    "        elif train_X.shape[0] != 0:\n",
    "            train_y = train_y.to(device)\n",
    "            loss = trainex_loss(train_output, train_y)\n",
    "        elif feedback_nom_X.shape[0] != 0:\n",
    "            feedback_nom_y = feedback_nom_y.to(device)\n",
    "            loss = known_loss(nom_output, feedback_nom_y)\n",
    "        elif feedback_nov_X.shape[0] != 0:\n",
    "            feedback_nov_y = feedback_nov_y.to(device)\n",
    "            loss = 0 # novel_loss(novel_output, feedback_nov_y)\n",
    "\n",
    "\n",
    "        loss /= images.shape[0]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "\n",
    "        if feedback_nov_X.shape[0] != 0:\n",
    "            novel_scores, novel_predictions = torch.max(novel_logits.data, 1)\n",
    "            novel_scores *= -1\n",
    "\n",
    "        if feedback_nom_X.shape[0] != 0:\n",
    "            nom_scores, nom_predictions = torch.max(nom_logits.data, 1)\n",
    "            nom_scores *= -1\n",
    "\n",
    "        if train_X.shape[0] != 0:\n",
    "            train_scores, nom_predictions = torch.max(train_logits.data, 1)\n",
    "            train_scores *= -1\n",
    "\n",
    "\n",
    "        if feedback_nov_X.shape[0] != 0:\n",
    "            ascores = ascores + [i for i in novel_scores]\n",
    "        if feedback_nom_X.shape[0] != 0:\n",
    "            nscores = nscores + [i for i in nom_scores]\n",
    "        if train_X.shape[0] != 0:\n",
    "            tscores = tscores + [i for i in train_scores]\n",
    "\n",
    "    ascores = torch.tensor(ascores)\n",
    "    nscores = torch.tensor(nscores)\n",
    "    tscores = torch.tensor(tscores)\n",
    "    y_true  = torch.hstack((torch.ones_like(ascores), torch.zeros_like(nscores), torch.zeros_like(tscores)))\n",
    "    y_score = torch.hstack((ascores, nscores, tscores))\n",
    "    train_auc = roc_auc_score(y_true, y_score)\n",
    "\n",
    "    return train_loss,None,train_auc\n",
    "\n",
    "# TODO: Fix the detection by using logits to compute scores instead of softmaxed logits\n",
    "def valid_detection_epoch(model,device,dataloader,trainex_loss,novel_loss,known_loss):\n",
    "    tau = -3\n",
    "    val_loss,val_correct=0.0,0\n",
    "    model.eval()\n",
    "\n",
    "    nscores = []\n",
    "    ascores = []\n",
    "    tscores = []\n",
    "\n",
    "    for images, labels_tensor in dataloader:\n",
    "\n",
    "        train_known_label_flags = labels_tensor[:,1]\n",
    "        labels = labels_tensor[:,0]\n",
    "\n",
    "        # To convert to detection setup\n",
    "        train_mask = (train_known_label_flags > 0) | ((train_known_label_flags == 0) & (labels != 0))\n",
    "        feedback_novel_mask = (train_known_label_flags == 0) & (labels == 0)\n",
    "        feedback_nomin_mask = torch.tensor([False for i in range(labels.shape[0])]) #(train_known_label_flags == 0) & (labels != 0)\n",
    "\n",
    "        # print(f'feedback_novel_mask: {feedback_novel_mask}')\n",
    "        # print(f'feedback_nomin_mask: {feedback_nomin_mask}')\n",
    "\n",
    "        train_X = images[torch.squeeze(train_mask),:]\n",
    "        train_y = labels[train_mask]\n",
    "        \n",
    "        # print(f'feedback_novel_mask shape: {feedback_novel_mask.shape}')\n",
    "        feedback_nov_X = images[torch.squeeze(feedback_novel_mask),:]\n",
    "        feedback_nov_y = labels[feedback_novel_mask]\n",
    "\n",
    "        # print(f'feedback_nomin_mask shape: {feedback_nomin_mask.shape}')\n",
    "        feedback_nom_X = images[torch.squeeze(feedback_nomin_mask),:]\n",
    "        feedback_nom_y = labels[feedback_nomin_mask]\n",
    "\n",
    "        # print(f'train_y shape: {train_y.shape}')\n",
    "        # print(f'feedback_nov_y shape: {feedback_nov_y.shape}')\n",
    "        # print(f'feedback_nom_y shape: {feedback_nom_y.shape}')\n",
    "\n",
    "        if feedback_nov_X.shape[0] != 0:\n",
    "            feedback_nov_X = feedback_nov_X.to(device)\n",
    "            novel_logits = model(feedback_nov_X)\n",
    "            novel_output = novel_logits #m(novel_logits)\n",
    "            # If the instance is anomalous, use uniform labeling\n",
    "            # NOTE: label matrix is (batch_size x num_nominal_classes)\n",
    "            feedback_nov_y = (1/num_known_classes)*torch.ones((feedback_nov_y.shape[0],num_known_classes))\n",
    "\n",
    "        if feedback_nom_X.shape[0] != 0:\n",
    "            feedback_nom_X = feedback_nom_X.to(device)\n",
    "            nom_logits = model(feedback_nom_X)\n",
    "            nom_output = nom_logits #m(nom_logits)\n",
    "            feedback_nom_y = torch.argmax(nom_output, dim=1)\n",
    "            #feedback_nom_y = torch.squeeze(one_hot(feedback_nom_y, num_known_classes).float())\n",
    "\n",
    "        if train_X.shape[0] != 0:\n",
    "            train_X = train_X.to(device)\n",
    "            train_logits = model(train_X)\n",
    "            train_output = train_logits #m(train_logits)\n",
    "\n",
    "        train_y = torch.squeeze(one_hot(train_y-1, num_known_classes).float())\n",
    "\n",
    "        # Compute the loss\n",
    "        if feedback_nov_X.shape[0] != 0 and feedback_nom_X.shape[0] != 0 and train_X.shape[0] != 0:\n",
    "            feedback_nov_y = feedback_nov_y.to(device)\n",
    "            feedback_nom_y = feedback_nom_y.to(device)\n",
    "            train_y = train_y.to(device)\n",
    "            loss = trainex_loss(train_output, train_y) \\\n",
    "                    + known_loss(nom_output, feedback_nom_y) #\\\n",
    "                    #+ novel_loss(novel_output, feedback_nov_y)\n",
    "        elif feedback_nom_X.shape[0] != 0 and train_X.shape[0] != 0:\n",
    "            feedback_nom_y = feedback_nom_y.to(device)\n",
    "            train_y = train_y.to(device)\n",
    "            loss = trainex_loss(train_output, train_y) \\\n",
    "                    + known_loss(nom_output, feedback_nom_y)\n",
    "        elif feedback_nov_X.shape[0] != 0 and train_X.shape[0] != 0:\n",
    "            feedback_nov_y = feedback_nov_y.to(device)\n",
    "            train_y = train_y.to(device)\n",
    "            loss = trainex_loss(train_output, train_y) #\\\n",
    "                    #+ novel_loss(novel_output, feedback_nov_y)\n",
    "        elif feedback_nov_X.shape[0] != 0 and feedback_nom_X.shape[0] != 0:\n",
    "            feedback_nov_y = feedback_nov_y.to(device)\n",
    "            feedback_nom_y = feedback_nom_y.to(device)\n",
    "            loss = known_loss(nom_output, feedback_nom_y) #\\\n",
    "                   # + novel_loss(novel_output, feedback_nov_y)\n",
    "        elif train_X.shape[0] != 0:\n",
    "            train_y = train_y.to(device)\n",
    "            loss = trainex_loss(train_output, train_y)\n",
    "        elif feedback_nom_X.shape[0] != 0:\n",
    "            feedback_nom_y = feedback_nom_y.to(device)\n",
    "            loss = known_loss(nom_output, feedback_nom_y)\n",
    "        elif feedback_nov_X.shape[0] != 0:\n",
    "            feedback_nov_y = feedback_nov_y.to(device)\n",
    "            loss = 0 #novel_loss(novel_output, feedback_nov_y)\n",
    "\n",
    "        loss /= images.shape[0]\n",
    "        val_loss += loss.item() * images.size(0)\n",
    "\n",
    "        if feedback_nov_X.shape[0] != 0:\n",
    "            novel_scores, novel_predictions = torch.max(novel_logits.data, 1)\n",
    "            novel_scores *= -1\n",
    "\n",
    "        if feedback_nom_X.shape[0] != 0:\n",
    "            nom_scores, nom_predictions = torch.max(nom_logits.data, 1)\n",
    "            nom_scores *= -1\n",
    "\n",
    "        if train_X.shape[0] != 0:\n",
    "            train_scores, nom_predictions = torch.max(train_logits.data, 1)\n",
    "            train_scores *= -1\n",
    "\n",
    "        if feedback_nov_X.shape[0] != 0:\n",
    "            ascores = ascores + [i for i in novel_scores]\n",
    "        if feedback_nom_X.shape[0] != 0:\n",
    "            nscores = nscores + [i for i in nom_scores]\n",
    "        if train_X.shape[0] != 0:\n",
    "            tscores = tscores + [i for i in train_scores]\n",
    "\n",
    "    ascores = torch.tensor(ascores)\n",
    "    nscores = torch.tensor(nscores)\n",
    "    tscores = torch.tensor(tscores)\n",
    "    y_true  = torch.hstack((torch.ones_like(ascores), torch.zeros_like(nscores), torch.zeros_like(tscores)))\n",
    "    y_score = torch.hstack((ascores, nscores, tscores))\n",
    "    val_auc = roc_auc_score(y_true, y_score)\n",
    "\n",
    "    return val_loss,None,val_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/tom/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1/100 Train Loss: 0.997 Val Loss: 0.655 Train AUC:0.597 Test AUC:0.797\n",
      "Epoch:2/100 Train Loss: 0.527 Val Loss: 0.513 Train AUC:0.782 Test AUC:0.883\n",
      "Epoch:3/100 Train Loss: 0.375 Val Loss: 0.408 Train AUC:0.818 Test AUC:0.843\n",
      "Epoch:4/100 Train Loss: 0.316 Val Loss: 0.356 Train AUC:0.871 Test AUC:0.857\n",
      "Epoch:5/100 Train Loss: 0.264 Val Loss: 0.328 Train AUC:0.863 Test AUC:0.847\n",
      "Epoch:6/100 Train Loss: 0.229 Val Loss: 0.338 Train AUC:0.905 Test AUC:0.877\n",
      "Epoch:7/100 Train Loss: 0.212 Val Loss: 0.305 Train AUC:0.905 Test AUC:0.856\n",
      "Epoch:8/100 Train Loss: 0.192 Val Loss: 0.295 Train AUC:0.920 Test AUC:0.832\n",
      "Epoch:9/100 Train Loss: 0.174 Val Loss: 0.267 Train AUC:0.926 Test AUC:0.834\n",
      "Epoch:10/100 Train Loss: 0.155 Val Loss: 0.289 Train AUC:0.961 Test AUC:0.854\n",
      "Epoch:11/100 Train Loss: 0.156 Val Loss: 0.295 Train AUC:0.933 Test AUC:0.863\n",
      "Epoch:12/100 Train Loss: 0.144 Val Loss: 0.272 Train AUC:0.950 Test AUC:0.867\n",
      "Epoch:13/100 Train Loss: 0.137 Val Loss: 0.285 Train AUC:0.939 Test AUC:0.863\n",
      "Epoch:14/100 Train Loss: 0.127 Val Loss: 0.276 Train AUC:0.967 Test AUC:0.873\n",
      "Epoch:15/100 Train Loss: 0.119 Val Loss: 0.263 Train AUC:0.972 Test AUC:0.860\n",
      "Epoch:16/100 Train Loss: 0.116 Val Loss: 0.287 Train AUC:0.976 Test AUC:0.858\n",
      "Epoch:17/100 Train Loss: 0.114 Val Loss: 0.268 Train AUC:0.968 Test AUC:0.831\n",
      "Epoch:18/100 Train Loss: 0.113 Val Loss: 0.246 Train AUC:0.977 Test AUC:0.842\n",
      "Epoch:19/100 Train Loss: 0.105 Val Loss: 0.237 Train AUC:0.983 Test AUC:0.807\n",
      "Epoch:20/100 Train Loss: 0.100 Val Loss: 0.269 Train AUC:0.987 Test AUC:0.854\n",
      "Epoch:21/100 Train Loss: 0.098 Val Loss: 0.276 Train AUC:0.989 Test AUC:0.840\n",
      "Epoch:22/100 Train Loss: 0.097 Val Loss: 0.273 Train AUC:0.986 Test AUC:0.858\n",
      "Epoch:23/100 Train Loss: 0.094 Val Loss: 0.267 Train AUC:0.989 Test AUC:0.853\n",
      "Epoch:24/100 Train Loss: 0.093 Val Loss: 0.252 Train AUC:0.987 Test AUC:0.839\n",
      "Epoch:25/100 Train Loss: 0.089 Val Loss: 0.267 Train AUC:0.994 Test AUC:0.862\n",
      "Epoch:26/100 Train Loss: 0.092 Val Loss: 0.264 Train AUC:0.991 Test AUC:0.864\n",
      "Epoch:27/100 Train Loss: 0.089 Val Loss: 0.241 Train AUC:0.991 Test AUC:0.858\n",
      "Epoch:28/100 Train Loss: 0.089 Val Loss: 0.251 Train AUC:0.992 Test AUC:0.832\n",
      "Epoch:29/100 Train Loss: 0.085 Val Loss: 0.271 Train AUC:0.992 Test AUC:0.881\n",
      "Epoch:30/100 Train Loss: 0.084 Val Loss: 0.252 Train AUC:0.994 Test AUC:0.864\n",
      "Epoch:31/100 Train Loss: 0.083 Val Loss: 0.246 Train AUC:0.995 Test AUC:0.836\n",
      "Epoch:32/100 Train Loss: 0.084 Val Loss: 0.249 Train AUC:0.993 Test AUC:0.850\n",
      "Epoch:33/100 Train Loss: 0.081 Val Loss: 0.261 Train AUC:0.994 Test AUC:0.829\n",
      "Epoch:34/100 Train Loss: 0.082 Val Loss: 0.233 Train AUC:0.995 Test AUC:0.847\n",
      "Epoch:35/100 Train Loss: 0.082 Val Loss: 0.257 Train AUC:0.995 Test AUC:0.881\n",
      "Epoch:36/100 Train Loss: 0.082 Val Loss: 0.251 Train AUC:0.993 Test AUC:0.872\n",
      "Epoch:37/100 Train Loss: 0.079 Val Loss: 0.247 Train AUC:0.996 Test AUC:0.872\n",
      "Epoch:38/100 Train Loss: 0.077 Val Loss: 0.262 Train AUC:0.994 Test AUC:0.891\n",
      "Epoch:39/100 Train Loss: 0.078 Val Loss: 0.259 Train AUC:0.995 Test AUC:0.869\n",
      "Epoch:40/100 Train Loss: 0.077 Val Loss: 0.285 Train AUC:0.996 Test AUC:0.887\n",
      "Epoch:41/100 Train Loss: 0.077 Val Loss: 0.243 Train AUC:0.995 Test AUC:0.833\n",
      "Epoch:42/100 Train Loss: 0.078 Val Loss: 0.239 Train AUC:0.994 Test AUC:0.854\n",
      "Epoch:43/100 Train Loss: 0.075 Val Loss: 0.275 Train AUC:0.994 Test AUC:0.871\n",
      "Epoch:44/100 Train Loss: 0.073 Val Loss: 0.247 Train AUC:0.997 Test AUC:0.861\n",
      "Epoch:45/100 Train Loss: 0.074 Val Loss: 0.301 Train AUC:0.996 Test AUC:0.868\n",
      "Epoch:46/100 Train Loss: 0.076 Val Loss: 0.271 Train AUC:0.995 Test AUC:0.881\n",
      "Epoch:47/100 Train Loss: 0.074 Val Loss: 0.257 Train AUC:0.996 Test AUC:0.871\n",
      "Epoch:48/100 Train Loss: 0.073 Val Loss: 0.245 Train AUC:0.996 Test AUC:0.844\n",
      "Epoch:49/100 Train Loss: 0.074 Val Loss: 0.244 Train AUC:0.996 Test AUC:0.848\n",
      "Epoch:50/100 Train Loss: 0.075 Val Loss: 0.268 Train AUC:0.996 Test AUC:0.881\n",
      "Epoch:51/100 Train Loss: 0.076 Val Loss: 0.257 Train AUC:0.996 Test AUC:0.864\n",
      "Epoch:52/100 Train Loss: 0.073 Val Loss: 0.227 Train AUC:0.996 Test AUC:0.839\n",
      "Epoch:53/100 Train Loss: 0.073 Val Loss: 0.282 Train AUC:0.996 Test AUC:0.867\n",
      "Epoch:54/100 Train Loss: 0.074 Val Loss: 0.239 Train AUC:0.995 Test AUC:0.885\n",
      "Epoch:55/100 Train Loss: 0.071 Val Loss: 0.261 Train AUC:0.995 Test AUC:0.880\n",
      "Epoch:56/100 Train Loss: 0.071 Val Loss: 0.267 Train AUC:0.996 Test AUC:0.866\n",
      "Epoch:57/100 Train Loss: 0.072 Val Loss: 0.305 Train AUC:0.996 Test AUC:0.864\n",
      "Epoch:58/100 Train Loss: 0.071 Val Loss: 0.256 Train AUC:0.996 Test AUC:0.870\n",
      "Epoch:59/100 Train Loss: 0.068 Val Loss: 0.255 Train AUC:0.997 Test AUC:0.855\n",
      "Epoch:60/100 Train Loss: 0.068 Val Loss: 0.259 Train AUC:0.998 Test AUC:0.869\n",
      "Epoch:61/100 Train Loss: 0.071 Val Loss: 0.246 Train AUC:0.996 Test AUC:0.872\n",
      "Epoch:62/100 Train Loss: 0.068 Val Loss: 0.246 Train AUC:0.997 Test AUC:0.839\n",
      "Epoch:63/100 Train Loss: 0.070 Val Loss: 0.254 Train AUC:0.997 Test AUC:0.863\n",
      "Epoch:64/100 Train Loss: 0.070 Val Loss: 0.260 Train AUC:0.996 Test AUC:0.868\n",
      "Epoch:65/100 Train Loss: 0.070 Val Loss: 0.277 Train AUC:0.997 Test AUC:0.879\n",
      "Epoch:66/100 Train Loss: 0.069 Val Loss: 0.257 Train AUC:0.996 Test AUC:0.833\n",
      "Epoch:67/100 Train Loss: 0.069 Val Loss: 0.267 Train AUC:0.996 Test AUC:0.887\n",
      "Epoch:68/100 Train Loss: 0.069 Val Loss: 0.248 Train AUC:0.997 Test AUC:0.838\n",
      "Epoch:69/100 Train Loss: 0.069 Val Loss: 0.254 Train AUC:0.996 Test AUC:0.886\n",
      "Epoch:70/100 Train Loss: 0.067 Val Loss: 0.267 Train AUC:0.997 Test AUC:0.874\n",
      "Epoch:71/100 Train Loss: 0.070 Val Loss: 0.262 Train AUC:0.996 Test AUC:0.845\n",
      "Epoch:72/100 Train Loss: 0.069 Val Loss: 0.251 Train AUC:0.996 Test AUC:0.864\n",
      "Epoch:73/100 Train Loss: 0.069 Val Loss: 0.303 Train AUC:0.996 Test AUC:0.871\n",
      "Epoch:74/100 Train Loss: 0.069 Val Loss: 0.264 Train AUC:0.996 Test AUC:0.840\n",
      "Epoch:75/100 Train Loss: 0.069 Val Loss: 0.344 Train AUC:0.996 Test AUC:0.893\n",
      "Epoch:76/100 Train Loss: 0.067 Val Loss: 0.258 Train AUC:0.996 Test AUC:0.880\n",
      "Epoch:77/100 Train Loss: 0.070 Val Loss: 0.241 Train AUC:0.996 Test AUC:0.876\n",
      "Epoch:78/100 Train Loss: 0.067 Val Loss: 0.230 Train AUC:0.999 Test AUC:0.831\n",
      "Epoch:79/100 Train Loss: 0.066 Val Loss: 0.252 Train AUC:0.997 Test AUC:0.852\n",
      "Epoch:80/100 Train Loss: 0.068 Val Loss: 0.244 Train AUC:0.996 Test AUC:0.870\n",
      "Epoch:81/100 Train Loss: 0.067 Val Loss: 0.239 Train AUC:0.998 Test AUC:0.868\n",
      "Epoch:82/100 Train Loss: 0.067 Val Loss: 0.251 Train AUC:0.997 Test AUC:0.866\n",
      "Epoch:83/100 Train Loss: 0.067 Val Loss: 0.272 Train AUC:0.996 Test AUC:0.883\n",
      "Epoch:84/100 Train Loss: 0.067 Val Loss: 0.291 Train AUC:0.997 Test AUC:0.858\n",
      "Epoch:85/100 Train Loss: 0.068 Val Loss: 0.261 Train AUC:0.997 Test AUC:0.870\n",
      "Epoch:86/100 Train Loss: 0.066 Val Loss: 0.248 Train AUC:0.998 Test AUC:0.870\n",
      "Epoch:87/100 Train Loss: 0.069 Val Loss: 0.255 Train AUC:0.995 Test AUC:0.861\n",
      "Epoch:88/100 Train Loss: 0.067 Val Loss: 0.264 Train AUC:0.997 Test AUC:0.843\n",
      "Epoch:89/100 Train Loss: 0.066 Val Loss: 0.271 Train AUC:0.998 Test AUC:0.884\n",
      "Epoch:90/100 Train Loss: 0.066 Val Loss: 0.309 Train AUC:0.998 Test AUC:0.874\n",
      "Epoch:91/100 Train Loss: 0.066 Val Loss: 0.251 Train AUC:0.997 Test AUC:0.818\n",
      "Epoch:92/100 Train Loss: 0.067 Val Loss: 0.273 Train AUC:0.997 Test AUC:0.873\n",
      "Epoch:93/100 Train Loss: 0.064 Val Loss: 0.260 Train AUC:0.997 Test AUC:0.849\n",
      "Epoch:94/100 Train Loss: 0.066 Val Loss: 0.265 Train AUC:0.998 Test AUC:0.858\n",
      "Epoch:95/100 Train Loss: 0.065 Val Loss: 0.254 Train AUC:0.999 Test AUC:0.853\n",
      "Epoch:96/100 Train Loss: 0.064 Val Loss: 0.283 Train AUC:0.998 Test AUC:0.865\n",
      "Epoch:97/100 Train Loss: 0.067 Val Loss: 0.257 Train AUC:0.995 Test AUC:0.877\n",
      "Epoch:98/100 Train Loss: 0.066 Val Loss: 0.264 Train AUC:0.998 Test AUC:0.881\n",
      "Epoch:99/100 Train Loss: 0.066 Val Loss: 0.264 Train AUC:0.998 Test AUC:0.871\n",
      "Epoch:100/100 Train Loss: 0.067 Val Loss: 0.267 Train AUC:0.997 Test AUC:0.855\n",
      "Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/tom/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1/100 Train Loss: 1.150 Val Loss: 0.655 Train AUC:0.544 Test AUC:0.827\n",
      "Epoch:2/100 Train Loss: 0.560 Val Loss: 0.425 Train AUC:0.738 Test AUC:0.861\n",
      "Epoch:3/100 Train Loss: 0.389 Val Loss: 0.364 Train AUC:0.798 Test AUC:0.875\n",
      "Epoch:4/100 Train Loss: 0.314 Val Loss: 0.335 Train AUC:0.837 Test AUC:0.877\n",
      "Epoch:5/100 Train Loss: 0.270 Val Loss: 0.295 Train AUC:0.876 Test AUC:0.852\n",
      "Epoch:6/100 Train Loss: 0.243 Val Loss: 0.318 Train AUC:0.899 Test AUC:0.871\n",
      "Epoch:7/100 Train Loss: 0.216 Val Loss: 0.259 Train AUC:0.909 Test AUC:0.844\n",
      "Epoch:8/100 Train Loss: 0.187 Val Loss: 0.338 Train AUC:0.913 Test AUC:0.895\n",
      "Epoch:9/100 Train Loss: 0.179 Val Loss: 0.262 Train AUC:0.927 Test AUC:0.859\n",
      "Epoch:10/100 Train Loss: 0.160 Val Loss: 0.271 Train AUC:0.935 Test AUC:0.881\n",
      "Epoch:11/100 Train Loss: 0.153 Val Loss: 0.259 Train AUC:0.932 Test AUC:0.859\n",
      "Epoch:12/100 Train Loss: 0.148 Val Loss: 0.245 Train AUC:0.950 Test AUC:0.852\n",
      "Epoch:13/100 Train Loss: 0.135 Val Loss: 0.249 Train AUC:0.942 Test AUC:0.864\n",
      "Epoch:14/100 Train Loss: 0.127 Val Loss: 0.259 Train AUC:0.956 Test AUC:0.852\n",
      "Epoch:15/100 Train Loss: 0.121 Val Loss: 0.247 Train AUC:0.955 Test AUC:0.861\n",
      "Epoch:16/100 Train Loss: 0.116 Val Loss: 0.246 Train AUC:0.968 Test AUC:0.858\n",
      "Epoch:17/100 Train Loss: 0.114 Val Loss: 0.252 Train AUC:0.965 Test AUC:0.859\n",
      "Epoch:18/100 Train Loss: 0.106 Val Loss: 0.248 Train AUC:0.977 Test AUC:0.861\n",
      "Epoch:19/100 Train Loss: 0.109 Val Loss: 0.244 Train AUC:0.970 Test AUC:0.852\n",
      "Epoch:20/100 Train Loss: 0.101 Val Loss: 0.256 Train AUC:0.981 Test AUC:0.867\n",
      "Epoch:21/100 Train Loss: 0.100 Val Loss: 0.328 Train AUC:0.982 Test AUC:0.889\n",
      "Epoch:22/100 Train Loss: 0.098 Val Loss: 0.249 Train AUC:0.978 Test AUC:0.868\n",
      "Epoch:23/100 Train Loss: 0.094 Val Loss: 0.240 Train AUC:0.992 Test AUC:0.884\n",
      "Epoch:24/100 Train Loss: 0.092 Val Loss: 0.278 Train AUC:0.985 Test AUC:0.893\n",
      "Epoch:25/100 Train Loss: 0.092 Val Loss: 0.255 Train AUC:0.987 Test AUC:0.889\n",
      "Epoch:26/100 Train Loss: 0.089 Val Loss: 0.242 Train AUC:0.987 Test AUC:0.850\n",
      "Epoch:27/100 Train Loss: 0.089 Val Loss: 0.260 Train AUC:0.987 Test AUC:0.882\n",
      "Epoch:28/100 Train Loss: 0.085 Val Loss: 0.247 Train AUC:0.991 Test AUC:0.900\n",
      "Epoch:29/100 Train Loss: 0.085 Val Loss: 0.254 Train AUC:0.992 Test AUC:0.881\n",
      "Epoch:30/100 Train Loss: 0.086 Val Loss: 0.244 Train AUC:0.991 Test AUC:0.873\n",
      "Epoch:31/100 Train Loss: 0.083 Val Loss: 0.247 Train AUC:0.993 Test AUC:0.870\n",
      "Epoch:32/100 Train Loss: 0.084 Val Loss: 0.253 Train AUC:0.993 Test AUC:0.906\n",
      "Epoch:33/100 Train Loss: 0.079 Val Loss: 0.242 Train AUC:0.996 Test AUC:0.881\n",
      "Epoch:34/100 Train Loss: 0.080 Val Loss: 0.270 Train AUC:0.992 Test AUC:0.878\n",
      "Epoch:35/100 Train Loss: 0.080 Val Loss: 0.244 Train AUC:0.993 Test AUC:0.885\n",
      "Epoch:36/100 Train Loss: 0.079 Val Loss: 0.248 Train AUC:0.995 Test AUC:0.889\n",
      "Epoch:37/100 Train Loss: 0.077 Val Loss: 0.242 Train AUC:0.997 Test AUC:0.890\n",
      "Epoch:38/100 Train Loss: 0.078 Val Loss: 0.254 Train AUC:0.995 Test AUC:0.893\n",
      "Epoch:39/100 Train Loss: 0.075 Val Loss: 0.274 Train AUC:0.997 Test AUC:0.908\n",
      "Epoch:40/100 Train Loss: 0.077 Val Loss: 0.260 Train AUC:0.995 Test AUC:0.899\n",
      "Epoch:41/100 Train Loss: 0.077 Val Loss: 0.241 Train AUC:0.994 Test AUC:0.883\n",
      "Epoch:42/100 Train Loss: 0.075 Val Loss: 0.260 Train AUC:0.995 Test AUC:0.868\n",
      "Epoch:43/100 Train Loss: 0.076 Val Loss: 0.271 Train AUC:0.993 Test AUC:0.863\n",
      "Epoch:44/100 Train Loss: 0.075 Val Loss: 0.264 Train AUC:0.996 Test AUC:0.895\n",
      "Epoch:45/100 Train Loss: 0.075 Val Loss: 0.263 Train AUC:0.995 Test AUC:0.882\n",
      "Epoch:46/100 Train Loss: 0.072 Val Loss: 0.253 Train AUC:0.996 Test AUC:0.887\n",
      "Epoch:47/100 Train Loss: 0.073 Val Loss: 0.270 Train AUC:0.996 Test AUC:0.915\n",
      "Epoch:48/100 Train Loss: 0.073 Val Loss: 0.255 Train AUC:0.996 Test AUC:0.888\n",
      "Epoch:49/100 Train Loss: 0.073 Val Loss: 0.276 Train AUC:0.995 Test AUC:0.909\n",
      "Epoch:50/100 Train Loss: 0.072 Val Loss: 0.268 Train AUC:0.996 Test AUC:0.895\n",
      "Epoch:51/100 Train Loss: 0.073 Val Loss: 0.258 Train AUC:0.996 Test AUC:0.877\n",
      "Epoch:52/100 Train Loss: 0.071 Val Loss: 0.258 Train AUC:0.995 Test AUC:0.897\n",
      "Epoch:53/100 Train Loss: 0.073 Val Loss: 0.254 Train AUC:0.995 Test AUC:0.892\n",
      "Epoch:54/100 Train Loss: 0.071 Val Loss: 0.256 Train AUC:0.995 Test AUC:0.899\n",
      "Epoch:55/100 Train Loss: 0.072 Val Loss: 0.280 Train AUC:0.995 Test AUC:0.911\n",
      "Epoch:56/100 Train Loss: 0.071 Val Loss: 0.251 Train AUC:0.997 Test AUC:0.885\n",
      "Epoch:57/100 Train Loss: 0.071 Val Loss: 0.272 Train AUC:0.997 Test AUC:0.914\n",
      "Epoch:58/100 Train Loss: 0.069 Val Loss: 0.258 Train AUC:0.996 Test AUC:0.904\n",
      "Epoch:59/100 Train Loss: 0.070 Val Loss: 0.263 Train AUC:0.995 Test AUC:0.892\n",
      "Epoch:60/100 Train Loss: 0.070 Val Loss: 0.269 Train AUC:0.996 Test AUC:0.903\n",
      "Epoch:61/100 Train Loss: 0.070 Val Loss: 0.254 Train AUC:0.995 Test AUC:0.906\n",
      "Epoch:62/100 Train Loss: 0.070 Val Loss: 0.254 Train AUC:0.996 Test AUC:0.880\n",
      "Epoch:63/100 Train Loss: 0.069 Val Loss: 0.239 Train AUC:0.997 Test AUC:0.903\n",
      "Epoch:64/100 Train Loss: 0.070 Val Loss: 0.268 Train AUC:0.997 Test AUC:0.920\n",
      "Epoch:65/100 Train Loss: 0.069 Val Loss: 0.265 Train AUC:0.996 Test AUC:0.906\n",
      "Epoch:66/100 Train Loss: 0.069 Val Loss: 0.253 Train AUC:0.997 Test AUC:0.904\n",
      "Epoch:67/100 Train Loss: 0.068 Val Loss: 0.259 Train AUC:0.996 Test AUC:0.918\n",
      "Epoch:68/100 Train Loss: 0.071 Val Loss: 0.260 Train AUC:0.996 Test AUC:0.908\n",
      "Epoch:69/100 Train Loss: 0.069 Val Loss: 0.275 Train AUC:0.996 Test AUC:0.917\n",
      "Epoch:70/100 Train Loss: 0.067 Val Loss: 0.271 Train AUC:0.997 Test AUC:0.932\n",
      "Epoch:71/100 Train Loss: 0.068 Val Loss: 0.255 Train AUC:0.997 Test AUC:0.897\n",
      "Epoch:72/100 Train Loss: 0.067 Val Loss: 0.247 Train AUC:0.997 Test AUC:0.889\n",
      "Epoch:73/100 Train Loss: 0.067 Val Loss: 0.289 Train AUC:0.998 Test AUC:0.925\n",
      "Epoch:74/100 Train Loss: 0.068 Val Loss: 0.274 Train AUC:0.997 Test AUC:0.915\n",
      "Epoch:75/100 Train Loss: 0.069 Val Loss: 0.253 Train AUC:0.996 Test AUC:0.908\n",
      "Epoch:76/100 Train Loss: 0.070 Val Loss: 0.286 Train AUC:0.996 Test AUC:0.894\n",
      "Epoch:77/100 Train Loss: 0.067 Val Loss: 0.267 Train AUC:0.997 Test AUC:0.914\n",
      "Epoch:78/100 Train Loss: 0.066 Val Loss: 0.269 Train AUC:0.996 Test AUC:0.908\n",
      "Epoch:79/100 Train Loss: 0.068 Val Loss: 0.263 Train AUC:0.995 Test AUC:0.913\n",
      "Epoch:80/100 Train Loss: 0.066 Val Loss: 0.260 Train AUC:0.997 Test AUC:0.901\n",
      "Epoch:81/100 Train Loss: 0.066 Val Loss: 0.279 Train AUC:0.997 Test AUC:0.865\n",
      "Epoch:82/100 Train Loss: 0.066 Val Loss: 0.272 Train AUC:0.997 Test AUC:0.909\n",
      "Epoch:83/100 Train Loss: 0.066 Val Loss: 0.260 Train AUC:0.996 Test AUC:0.915\n",
      "Epoch:84/100 Train Loss: 0.066 Val Loss: 0.251 Train AUC:0.996 Test AUC:0.906\n",
      "Epoch:85/100 Train Loss: 0.065 Val Loss: 0.254 Train AUC:0.998 Test AUC:0.918\n",
      "Epoch:86/100 Train Loss: 0.066 Val Loss: 0.252 Train AUC:0.997 Test AUC:0.902\n",
      "Epoch:87/100 Train Loss: 0.065 Val Loss: 0.266 Train AUC:0.997 Test AUC:0.901\n",
      "Epoch:88/100 Train Loss: 0.066 Val Loss: 0.256 Train AUC:0.996 Test AUC:0.870\n",
      "Epoch:89/100 Train Loss: 0.065 Val Loss: 0.250 Train AUC:0.997 Test AUC:0.892\n",
      "Epoch:90/100 Train Loss: 0.065 Val Loss: 0.251 Train AUC:0.996 Test AUC:0.888\n",
      "Epoch:91/100 Train Loss: 0.066 Val Loss: 0.253 Train AUC:0.996 Test AUC:0.888\n",
      "Epoch:92/100 Train Loss: 0.064 Val Loss: 0.254 Train AUC:0.998 Test AUC:0.919\n",
      "Epoch:93/100 Train Loss: 0.064 Val Loss: 0.255 Train AUC:0.998 Test AUC:0.905\n",
      "Epoch:94/100 Train Loss: 0.063 Val Loss: 0.258 Train AUC:0.998 Test AUC:0.904\n",
      "Epoch:95/100 Train Loss: 0.065 Val Loss: 0.256 Train AUC:0.998 Test AUC:0.890\n",
      "Epoch:96/100 Train Loss: 0.065 Val Loss: 0.269 Train AUC:0.997 Test AUC:0.915\n",
      "Epoch:97/100 Train Loss: 0.064 Val Loss: 0.249 Train AUC:0.998 Test AUC:0.900\n",
      "Epoch:98/100 Train Loss: 0.066 Val Loss: 0.269 Train AUC:0.997 Test AUC:0.920\n",
      "Epoch:99/100 Train Loss: 0.065 Val Loss: 0.284 Train AUC:0.996 Test AUC:0.907\n",
      "Epoch:100/100 Train Loss: 0.065 Val Loss: 0.286 Train AUC:0.996 Test AUC:0.920\n",
      "Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/tom/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1/100 Train Loss: 1.059 Val Loss: 0.706 Train AUC:0.565 Test AUC:0.754\n",
      "Epoch:2/100 Train Loss: 0.541 Val Loss: 0.483 Train AUC:0.717 Test AUC:0.774\n",
      "Epoch:3/100 Train Loss: 0.374 Val Loss: 0.430 Train AUC:0.826 Test AUC:0.752\n",
      "Epoch:4/100 Train Loss: 0.310 Val Loss: 0.398 Train AUC:0.824 Test AUC:0.812\n",
      "Epoch:5/100 Train Loss: 0.257 Val Loss: 0.350 Train AUC:0.867 Test AUC:0.816\n",
      "Epoch:6/100 Train Loss: 0.225 Val Loss: 0.331 Train AUC:0.888 Test AUC:0.816\n",
      "Epoch:7/100 Train Loss: 0.199 Val Loss: 0.303 Train AUC:0.929 Test AUC:0.805\n",
      "Epoch:8/100 Train Loss: 0.189 Val Loss: 0.313 Train AUC:0.895 Test AUC:0.801\n",
      "Epoch:9/100 Train Loss: 0.160 Val Loss: 0.295 Train AUC:0.931 Test AUC:0.796\n",
      "Epoch:10/100 Train Loss: 0.157 Val Loss: 0.335 Train AUC:0.925 Test AUC:0.887\n",
      "Epoch:11/100 Train Loss: 0.138 Val Loss: 0.325 Train AUC:0.947 Test AUC:0.847\n",
      "Epoch:12/100 Train Loss: 0.129 Val Loss: 0.379 Train AUC:0.957 Test AUC:0.839\n",
      "Epoch:13/100 Train Loss: 0.125 Val Loss: 0.273 Train AUC:0.957 Test AUC:0.843\n",
      "Epoch:14/100 Train Loss: 0.117 Val Loss: 0.278 Train AUC:0.969 Test AUC:0.821\n",
      "Epoch:15/100 Train Loss: 0.110 Val Loss: 0.311 Train AUC:0.973 Test AUC:0.862\n",
      "Epoch:16/100 Train Loss: 0.103 Val Loss: 0.309 Train AUC:0.982 Test AUC:0.880\n",
      "Epoch:17/100 Train Loss: 0.104 Val Loss: 0.338 Train AUC:0.976 Test AUC:0.896\n",
      "Epoch:18/100 Train Loss: 0.097 Val Loss: 0.304 Train AUC:0.977 Test AUC:0.852\n",
      "Epoch:19/100 Train Loss: 0.096 Val Loss: 0.284 Train AUC:0.977 Test AUC:0.895\n",
      "Epoch:20/100 Train Loss: 0.094 Val Loss: 0.309 Train AUC:0.978 Test AUC:0.881\n",
      "Epoch:21/100 Train Loss: 0.086 Val Loss: 0.290 Train AUC:0.984 Test AUC:0.877\n",
      "Epoch:22/100 Train Loss: 0.085 Val Loss: 0.283 Train AUC:0.985 Test AUC:0.882\n",
      "Epoch:23/100 Train Loss: 0.084 Val Loss: 0.283 Train AUC:0.989 Test AUC:0.851\n",
      "Epoch:24/100 Train Loss: 0.081 Val Loss: 0.273 Train AUC:0.990 Test AUC:0.911\n",
      "Epoch:25/100 Train Loss: 0.079 Val Loss: 0.278 Train AUC:0.987 Test AUC:0.880\n",
      "Epoch:26/100 Train Loss: 0.073 Val Loss: 0.280 Train AUC:0.994 Test AUC:0.900\n",
      "Epoch:27/100 Train Loss: 0.078 Val Loss: 0.301 Train AUC:0.990 Test AUC:0.900\n",
      "Epoch:28/100 Train Loss: 0.074 Val Loss: 0.297 Train AUC:0.994 Test AUC:0.904\n",
      "Epoch:29/100 Train Loss: 0.073 Val Loss: 0.319 Train AUC:0.993 Test AUC:0.915\n",
      "Epoch:30/100 Train Loss: 0.073 Val Loss: 0.275 Train AUC:0.995 Test AUC:0.864\n",
      "Epoch:31/100 Train Loss: 0.071 Val Loss: 0.282 Train AUC:0.993 Test AUC:0.887\n",
      "Epoch:32/100 Train Loss: 0.069 Val Loss: 0.288 Train AUC:0.995 Test AUC:0.904\n",
      "Epoch:33/100 Train Loss: 0.071 Val Loss: 0.309 Train AUC:0.995 Test AUC:0.910\n",
      "Epoch:34/100 Train Loss: 0.070 Val Loss: 0.301 Train AUC:0.993 Test AUC:0.882\n",
      "Epoch:35/100 Train Loss: 0.068 Val Loss: 0.301 Train AUC:0.995 Test AUC:0.865\n",
      "Epoch:36/100 Train Loss: 0.067 Val Loss: 0.306 Train AUC:0.996 Test AUC:0.892\n",
      "Epoch:37/100 Train Loss: 0.067 Val Loss: 0.278 Train AUC:0.994 Test AUC:0.913\n",
      "Epoch:38/100 Train Loss: 0.066 Val Loss: 0.278 Train AUC:0.996 Test AUC:0.894\n",
      "Epoch:39/100 Train Loss: 0.066 Val Loss: 0.287 Train AUC:0.996 Test AUC:0.897\n",
      "Epoch:40/100 Train Loss: 0.063 Val Loss: 0.285 Train AUC:0.996 Test AUC:0.901\n",
      "Epoch:41/100 Train Loss: 0.064 Val Loss: 0.283 Train AUC:0.995 Test AUC:0.899\n",
      "Epoch:42/100 Train Loss: 0.064 Val Loss: 0.318 Train AUC:0.995 Test AUC:0.906\n",
      "Epoch:43/100 Train Loss: 0.062 Val Loss: 0.283 Train AUC:0.997 Test AUC:0.879\n",
      "Epoch:44/100 Train Loss: 0.061 Val Loss: 0.284 Train AUC:0.996 Test AUC:0.910\n",
      "Epoch:45/100 Train Loss: 0.065 Val Loss: 0.283 Train AUC:0.994 Test AUC:0.877\n",
      "Epoch:46/100 Train Loss: 0.064 Val Loss: 0.298 Train AUC:0.996 Test AUC:0.889\n",
      "Epoch:47/100 Train Loss: 0.064 Val Loss: 0.289 Train AUC:0.996 Test AUC:0.906\n",
      "Epoch:48/100 Train Loss: 0.063 Val Loss: 0.290 Train AUC:0.997 Test AUC:0.895\n",
      "Epoch:49/100 Train Loss: 0.063 Val Loss: 0.282 Train AUC:0.995 Test AUC:0.898\n",
      "Epoch:50/100 Train Loss: 0.062 Val Loss: 0.315 Train AUC:0.996 Test AUC:0.897\n",
      "Epoch:51/100 Train Loss: 0.060 Val Loss: 0.295 Train AUC:0.997 Test AUC:0.887\n",
      "Epoch:52/100 Train Loss: 0.062 Val Loss: 0.298 Train AUC:0.996 Test AUC:0.898\n",
      "Epoch:53/100 Train Loss: 0.061 Val Loss: 0.294 Train AUC:0.997 Test AUC:0.910\n",
      "Epoch:54/100 Train Loss: 0.058 Val Loss: 0.285 Train AUC:0.998 Test AUC:0.925\n",
      "Epoch:55/100 Train Loss: 0.059 Val Loss: 0.285 Train AUC:0.998 Test AUC:0.910\n",
      "Epoch:56/100 Train Loss: 0.060 Val Loss: 0.291 Train AUC:0.995 Test AUC:0.849\n",
      "Epoch:57/100 Train Loss: 0.058 Val Loss: 0.289 Train AUC:0.998 Test AUC:0.905\n",
      "Epoch:58/100 Train Loss: 0.059 Val Loss: 0.287 Train AUC:0.997 Test AUC:0.883\n",
      "Epoch:59/100 Train Loss: 0.058 Val Loss: 0.300 Train AUC:0.997 Test AUC:0.880\n",
      "Epoch:60/100 Train Loss: 0.058 Val Loss: 0.297 Train AUC:0.997 Test AUC:0.869\n",
      "Epoch:61/100 Train Loss: 0.059 Val Loss: 0.288 Train AUC:0.996 Test AUC:0.899\n",
      "Epoch:62/100 Train Loss: 0.058 Val Loss: 0.298 Train AUC:0.997 Test AUC:0.903\n",
      "Epoch:63/100 Train Loss: 0.057 Val Loss: 0.322 Train AUC:0.996 Test AUC:0.921\n",
      "Epoch:64/100 Train Loss: 0.057 Val Loss: 0.284 Train AUC:0.998 Test AUC:0.890\n",
      "Epoch:65/100 Train Loss: 0.057 Val Loss: 0.314 Train AUC:0.998 Test AUC:0.889\n",
      "Epoch:66/100 Train Loss: 0.055 Val Loss: 0.310 Train AUC:0.997 Test AUC:0.895\n",
      "Epoch:67/100 Train Loss: 0.056 Val Loss: 0.320 Train AUC:0.997 Test AUC:0.847\n",
      "Epoch:68/100 Train Loss: 0.058 Val Loss: 0.286 Train AUC:0.998 Test AUC:0.913\n",
      "Epoch:69/100 Train Loss: 0.059 Val Loss: 0.294 Train AUC:0.996 Test AUC:0.895\n",
      "Epoch:70/100 Train Loss: 0.058 Val Loss: 0.310 Train AUC:0.997 Test AUC:0.890\n",
      "Epoch:71/100 Train Loss: 0.056 Val Loss: 0.289 Train AUC:0.998 Test AUC:0.880\n",
      "Epoch:72/100 Train Loss: 0.056 Val Loss: 0.301 Train AUC:0.997 Test AUC:0.915\n",
      "Epoch:73/100 Train Loss: 0.056 Val Loss: 0.327 Train AUC:0.997 Test AUC:0.875\n",
      "Epoch:74/100 Train Loss: 0.056 Val Loss: 0.294 Train AUC:0.997 Test AUC:0.914\n",
      "Epoch:75/100 Train Loss: 0.055 Val Loss: 0.327 Train AUC:0.998 Test AUC:0.911\n",
      "Epoch:76/100 Train Loss: 0.056 Val Loss: 0.299 Train AUC:0.997 Test AUC:0.923\n",
      "Epoch:77/100 Train Loss: 0.058 Val Loss: 0.298 Train AUC:0.996 Test AUC:0.869\n",
      "Epoch:78/100 Train Loss: 0.057 Val Loss: 0.320 Train AUC:0.998 Test AUC:0.906\n",
      "Epoch:79/100 Train Loss: 0.057 Val Loss: 0.308 Train AUC:0.997 Test AUC:0.888\n",
      "Epoch:80/100 Train Loss: 0.056 Val Loss: 0.314 Train AUC:0.997 Test AUC:0.911\n",
      "Epoch:81/100 Train Loss: 0.055 Val Loss: 0.299 Train AUC:0.999 Test AUC:0.889\n",
      "Epoch:82/100 Train Loss: 0.056 Val Loss: 0.285 Train AUC:0.998 Test AUC:0.886\n",
      "Epoch:83/100 Train Loss: 0.055 Val Loss: 0.312 Train AUC:0.997 Test AUC:0.881\n",
      "Epoch:84/100 Train Loss: 0.057 Val Loss: 0.300 Train AUC:0.997 Test AUC:0.920\n",
      "Epoch:85/100 Train Loss: 0.055 Val Loss: 0.304 Train AUC:0.998 Test AUC:0.901\n",
      "Epoch:86/100 Train Loss: 0.056 Val Loss: 0.299 Train AUC:0.997 Test AUC:0.923\n",
      "Epoch:87/100 Train Loss: 0.055 Val Loss: 0.311 Train AUC:0.998 Test AUC:0.933\n",
      "Epoch:88/100 Train Loss: 0.055 Val Loss: 0.294 Train AUC:0.997 Test AUC:0.920\n",
      "Epoch:89/100 Train Loss: 0.055 Val Loss: 0.291 Train AUC:0.997 Test AUC:0.909\n",
      "Epoch:90/100 Train Loss: 0.055 Val Loss: 0.322 Train AUC:0.997 Test AUC:0.889\n",
      "Epoch:91/100 Train Loss: 0.056 Val Loss: 0.288 Train AUC:0.997 Test AUC:0.888\n",
      "Epoch:92/100 Train Loss: 0.056 Val Loss: 0.305 Train AUC:0.997 Test AUC:0.892\n",
      "Epoch:93/100 Train Loss: 0.055 Val Loss: 0.294 Train AUC:0.997 Test AUC:0.860\n",
      "Epoch:94/100 Train Loss: 0.054 Val Loss: 0.308 Train AUC:0.998 Test AUC:0.889\n",
      "Epoch:95/100 Train Loss: 0.055 Val Loss: 0.312 Train AUC:0.997 Test AUC:0.919\n",
      "Epoch:96/100 Train Loss: 0.058 Val Loss: 0.308 Train AUC:0.997 Test AUC:0.866\n",
      "Epoch:97/100 Train Loss: 0.055 Val Loss: 0.300 Train AUC:0.998 Test AUC:0.916\n",
      "Epoch:98/100 Train Loss: 0.055 Val Loss: 0.311 Train AUC:0.997 Test AUC:0.925\n",
      "Epoch:99/100 Train Loss: 0.054 Val Loss: 0.312 Train AUC:0.998 Test AUC:0.891\n",
      "Epoch:100/100 Train Loss: 0.054 Val Loss: 0.305 Train AUC:0.999 Test AUC:0.889\n",
      "Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/tom/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1/100 Train Loss: 1.011 Val Loss: 0.634 Train AUC:0.547 Test AUC:0.786\n",
      "Epoch:2/100 Train Loss: 0.538 Val Loss: 0.420 Train AUC:0.745 Test AUC:0.803\n",
      "Epoch:3/100 Train Loss: 0.384 Val Loss: 0.370 Train AUC:0.838 Test AUC:0.805\n",
      "Epoch:4/100 Train Loss: 0.313 Val Loss: 0.317 Train AUC:0.851 Test AUC:0.829\n",
      "Epoch:5/100 Train Loss: 0.265 Val Loss: 0.312 Train AUC:0.869 Test AUC:0.801\n",
      "Epoch:6/100 Train Loss: 0.232 Val Loss: 0.292 Train AUC:0.895 Test AUC:0.806\n",
      "Epoch:7/100 Train Loss: 0.218 Val Loss: 0.284 Train AUC:0.907 Test AUC:0.832\n",
      "Epoch:8/100 Train Loss: 0.194 Val Loss: 0.266 Train AUC:0.908 Test AUC:0.846\n",
      "Epoch:9/100 Train Loss: 0.172 Val Loss: 0.279 Train AUC:0.923 Test AUC:0.854\n",
      "Epoch:10/100 Train Loss: 0.167 Val Loss: 0.294 Train AUC:0.934 Test AUC:0.793\n",
      "Epoch:11/100 Train Loss: 0.147 Val Loss: 0.296 Train AUC:0.939 Test AUC:0.845\n",
      "Epoch:12/100 Train Loss: 0.145 Val Loss: 0.280 Train AUC:0.943 Test AUC:0.834\n",
      "Epoch:13/100 Train Loss: 0.137 Val Loss: 0.261 Train AUC:0.949 Test AUC:0.826\n",
      "Epoch:14/100 Train Loss: 0.125 Val Loss: 0.256 Train AUC:0.966 Test AUC:0.861\n",
      "Epoch:15/100 Train Loss: 0.124 Val Loss: 0.304 Train AUC:0.958 Test AUC:0.841\n",
      "Epoch:16/100 Train Loss: 0.113 Val Loss: 0.257 Train AUC:0.975 Test AUC:0.816\n",
      "Epoch:17/100 Train Loss: 0.111 Val Loss: 0.278 Train AUC:0.975 Test AUC:0.862\n",
      "Epoch:18/100 Train Loss: 0.106 Val Loss: 0.252 Train AUC:0.978 Test AUC:0.842\n",
      "Epoch:19/100 Train Loss: 0.102 Val Loss: 0.250 Train AUC:0.970 Test AUC:0.870\n",
      "Epoch:20/100 Train Loss: 0.100 Val Loss: 0.257 Train AUC:0.980 Test AUC:0.869\n",
      "Epoch:21/100 Train Loss: 0.098 Val Loss: 0.274 Train AUC:0.984 Test AUC:0.881\n",
      "Epoch:22/100 Train Loss: 0.092 Val Loss: 0.257 Train AUC:0.990 Test AUC:0.832\n",
      "Epoch:23/100 Train Loss: 0.092 Val Loss: 0.261 Train AUC:0.991 Test AUC:0.859\n",
      "Epoch:24/100 Train Loss: 0.090 Val Loss: 0.271 Train AUC:0.990 Test AUC:0.843\n",
      "Epoch:25/100 Train Loss: 0.091 Val Loss: 0.296 Train AUC:0.988 Test AUC:0.844\n",
      "Epoch:26/100 Train Loss: 0.092 Val Loss: 0.286 Train AUC:0.989 Test AUC:0.856\n",
      "Epoch:27/100 Train Loss: 0.088 Val Loss: 0.267 Train AUC:0.990 Test AUC:0.873\n",
      "Epoch:28/100 Train Loss: 0.086 Val Loss: 0.267 Train AUC:0.992 Test AUC:0.823\n",
      "Epoch:29/100 Train Loss: 0.084 Val Loss: 0.263 Train AUC:0.992 Test AUC:0.816\n",
      "Epoch:30/100 Train Loss: 0.084 Val Loss: 0.257 Train AUC:0.992 Test AUC:0.832\n",
      "Epoch:31/100 Train Loss: 0.081 Val Loss: 0.256 Train AUC:0.992 Test AUC:0.865\n",
      "Epoch:32/100 Train Loss: 0.078 Val Loss: 0.267 Train AUC:0.995 Test AUC:0.888\n",
      "Epoch:33/100 Train Loss: 0.080 Val Loss: 0.264 Train AUC:0.994 Test AUC:0.817\n",
      "Epoch:34/100 Train Loss: 0.079 Val Loss: 0.282 Train AUC:0.995 Test AUC:0.846\n",
      "Epoch:35/100 Train Loss: 0.078 Val Loss: 0.273 Train AUC:0.995 Test AUC:0.869\n",
      "Epoch:36/100 Train Loss: 0.077 Val Loss: 0.290 Train AUC:0.994 Test AUC:0.804\n",
      "Epoch:37/100 Train Loss: 0.075 Val Loss: 0.284 Train AUC:0.996 Test AUC:0.883\n",
      "Epoch:38/100 Train Loss: 0.078 Val Loss: 0.290 Train AUC:0.992 Test AUC:0.836\n",
      "Epoch:39/100 Train Loss: 0.075 Val Loss: 0.293 Train AUC:0.995 Test AUC:0.840\n",
      "Epoch:40/100 Train Loss: 0.078 Val Loss: 0.260 Train AUC:0.994 Test AUC:0.877\n",
      "Epoch:41/100 Train Loss: 0.072 Val Loss: 0.265 Train AUC:0.996 Test AUC:0.881\n",
      "Epoch:42/100 Train Loss: 0.073 Val Loss: 0.288 Train AUC:0.995 Test AUC:0.816\n",
      "Epoch:43/100 Train Loss: 0.074 Val Loss: 0.269 Train AUC:0.995 Test AUC:0.864\n",
      "Epoch:44/100 Train Loss: 0.072 Val Loss: 0.259 Train AUC:0.994 Test AUC:0.887\n",
      "Epoch:45/100 Train Loss: 0.072 Val Loss: 0.282 Train AUC:0.995 Test AUC:0.830\n",
      "Epoch:46/100 Train Loss: 0.071 Val Loss: 0.268 Train AUC:0.995 Test AUC:0.852\n",
      "Epoch:47/100 Train Loss: 0.071 Val Loss: 0.284 Train AUC:0.994 Test AUC:0.836\n",
      "Epoch:48/100 Train Loss: 0.072 Val Loss: 0.321 Train AUC:0.995 Test AUC:0.831\n",
      "Epoch:49/100 Train Loss: 0.072 Val Loss: 0.280 Train AUC:0.996 Test AUC:0.839\n",
      "Epoch:50/100 Train Loss: 0.070 Val Loss: 0.286 Train AUC:0.995 Test AUC:0.862\n",
      "Epoch:51/100 Train Loss: 0.070 Val Loss: 0.284 Train AUC:0.996 Test AUC:0.881\n",
      "Epoch:52/100 Train Loss: 0.069 Val Loss: 0.294 Train AUC:0.997 Test AUC:0.874\n",
      "Epoch:53/100 Train Loss: 0.069 Val Loss: 0.297 Train AUC:0.997 Test AUC:0.874\n",
      "Epoch:54/100 Train Loss: 0.068 Val Loss: 0.294 Train AUC:0.996 Test AUC:0.803\n",
      "Epoch:55/100 Train Loss: 0.071 Val Loss: 0.298 Train AUC:0.994 Test AUC:0.909\n",
      "Epoch:56/100 Train Loss: 0.070 Val Loss: 0.293 Train AUC:0.996 Test AUC:0.884\n",
      "Epoch:57/100 Train Loss: 0.069 Val Loss: 0.289 Train AUC:0.996 Test AUC:0.879\n",
      "Epoch:58/100 Train Loss: 0.068 Val Loss: 0.279 Train AUC:0.996 Test AUC:0.851\n",
      "Epoch:59/100 Train Loss: 0.069 Val Loss: 0.299 Train AUC:0.994 Test AUC:0.842\n",
      "Epoch:60/100 Train Loss: 0.067 Val Loss: 0.282 Train AUC:0.996 Test AUC:0.846\n",
      "Epoch:61/100 Train Loss: 0.068 Val Loss: 0.270 Train AUC:0.997 Test AUC:0.852\n",
      "Epoch:62/100 Train Loss: 0.069 Val Loss: 0.277 Train AUC:0.996 Test AUC:0.896\n",
      "Epoch:63/100 Train Loss: 0.069 Val Loss: 0.284 Train AUC:0.995 Test AUC:0.836\n",
      "Epoch:64/100 Train Loss: 0.068 Val Loss: 0.292 Train AUC:0.995 Test AUC:0.850\n",
      "Epoch:65/100 Train Loss: 0.065 Val Loss: 0.278 Train AUC:0.997 Test AUC:0.877\n",
      "Epoch:66/100 Train Loss: 0.069 Val Loss: 0.270 Train AUC:0.995 Test AUC:0.847\n",
      "Epoch:67/100 Train Loss: 0.068 Val Loss: 0.296 Train AUC:0.995 Test AUC:0.886\n",
      "Epoch:68/100 Train Loss: 0.066 Val Loss: 0.276 Train AUC:0.997 Test AUC:0.861\n",
      "Epoch:69/100 Train Loss: 0.067 Val Loss: 0.275 Train AUC:0.996 Test AUC:0.877\n",
      "Epoch:70/100 Train Loss: 0.065 Val Loss: 0.307 Train AUC:0.996 Test AUC:0.895\n",
      "Epoch:71/100 Train Loss: 0.066 Val Loss: 0.354 Train AUC:0.996 Test AUC:0.891\n",
      "Epoch:72/100 Train Loss: 0.067 Val Loss: 0.287 Train AUC:0.996 Test AUC:0.890\n",
      "Epoch:73/100 Train Loss: 0.064 Val Loss: 0.280 Train AUC:0.998 Test AUC:0.872\n",
      "Epoch:74/100 Train Loss: 0.065 Val Loss: 0.292 Train AUC:0.996 Test AUC:0.906\n",
      "Epoch:75/100 Train Loss: 0.065 Val Loss: 0.292 Train AUC:0.997 Test AUC:0.849\n",
      "Epoch:76/100 Train Loss: 0.066 Val Loss: 0.333 Train AUC:0.995 Test AUC:0.869\n",
      "Epoch:77/100 Train Loss: 0.063 Val Loss: 0.289 Train AUC:0.997 Test AUC:0.883\n",
      "Epoch:78/100 Train Loss: 0.061 Val Loss: 0.293 Train AUC:0.998 Test AUC:0.884\n",
      "Epoch:79/100 Train Loss: 0.065 Val Loss: 0.287 Train AUC:0.995 Test AUC:0.875\n",
      "Epoch:80/100 Train Loss: 0.064 Val Loss: 0.327 Train AUC:0.995 Test AUC:0.843\n",
      "Epoch:81/100 Train Loss: 0.064 Val Loss: 0.302 Train AUC:0.997 Test AUC:0.884\n",
      "Epoch:82/100 Train Loss: 0.064 Val Loss: 0.296 Train AUC:0.996 Test AUC:0.841\n",
      "Epoch:83/100 Train Loss: 0.064 Val Loss: 0.282 Train AUC:0.997 Test AUC:0.856\n",
      "Epoch:84/100 Train Loss: 0.065 Val Loss: 0.298 Train AUC:0.997 Test AUC:0.898\n",
      "Epoch:85/100 Train Loss: 0.065 Val Loss: 0.284 Train AUC:0.997 Test AUC:0.866\n",
      "Epoch:86/100 Train Loss: 0.064 Val Loss: 0.286 Train AUC:0.996 Test AUC:0.856\n",
      "Epoch:87/100 Train Loss: 0.064 Val Loss: 0.360 Train AUC:0.996 Test AUC:0.870\n",
      "Epoch:88/100 Train Loss: 0.064 Val Loss: 0.279 Train AUC:0.997 Test AUC:0.839\n",
      "Epoch:89/100 Train Loss: 0.067 Val Loss: 0.331 Train AUC:0.996 Test AUC:0.865\n",
      "Epoch:90/100 Train Loss: 0.062 Val Loss: 0.300 Train AUC:0.997 Test AUC:0.894\n",
      "Epoch:91/100 Train Loss: 0.064 Val Loss: 0.283 Train AUC:0.996 Test AUC:0.832\n",
      "Epoch:92/100 Train Loss: 0.064 Val Loss: 0.286 Train AUC:0.997 Test AUC:0.841\n",
      "Epoch:93/100 Train Loss: 0.064 Val Loss: 0.304 Train AUC:0.997 Test AUC:0.830\n",
      "Epoch:94/100 Train Loss: 0.063 Val Loss: 0.299 Train AUC:0.997 Test AUC:0.855\n",
      "Epoch:95/100 Train Loss: 0.063 Val Loss: 0.284 Train AUC:0.997 Test AUC:0.860\n",
      "Epoch:96/100 Train Loss: 0.065 Val Loss: 0.291 Train AUC:0.996 Test AUC:0.881\n",
      "Epoch:97/100 Train Loss: 0.064 Val Loss: 0.321 Train AUC:0.996 Test AUC:0.885\n",
      "Epoch:98/100 Train Loss: 0.064 Val Loss: 0.299 Train AUC:0.997 Test AUC:0.844\n",
      "Epoch:99/100 Train Loss: 0.063 Val Loss: 0.341 Train AUC:0.996 Test AUC:0.798\n",
      "Epoch:100/100 Train Loss: 0.065 Val Loss: 0.306 Train AUC:0.996 Test AUC:0.879\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "novel_loss = nn.CrossEntropyLoss(reduction='sum')\n",
    "known_loss = nn.CrossEntropyLoss(label_smoothing=alpha, reduction='sum')\n",
    "trainex_loss = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(dset)))):\n",
    "\n",
    "    print('Fold {}'.format(fold + 1))\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler  = SubsetRandomSampler(val_idx)\n",
    "    train_loader  = DataLoader(dset, batch_size=batch_size, sampler=train_sampler)\n",
    "    test_loader   = DataLoader(dset, batch_size=batch_size, sampler=test_sampler)\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, num_known_classes)\n",
    "    model.to(device)\n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.0005, momentum=0.9, weight_decay=0.001, nesterov=True)\n",
    "\n",
    "    history = {'train_loss': [], 'test_loss': [],'train_acc':[],'test_acc':[],'train_auc':[],'test_auc':[]}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_correct, train_auc=train_detection_epoch_orig(model,device,train_loader,trainex_loss,novel_loss,known_loss,optimizer)\n",
    "        with torch.no_grad():\n",
    "            test_loss, test_correct, test_auc=valid_detection_epoch_orig(model,device,test_loader,trainex_loss,novel_loss,known_loss)\n",
    "\n",
    "        train_loss = train_loss / len(train_loader.sampler)\n",
    "        #train_acc = train_correct / len(train_loader.sampler) * 100\n",
    "        test_loss = test_loss / len(test_loader.sampler)\n",
    "        #test_acc = test_correct / len(test_loader.sampler) * 100\n",
    "\n",
    "        print(\"Epoch:{}/{} Train Loss: {:.3f} Val Loss: {:.3f} Train AUC:{:.3f} Test AUC:{:.3f}\".format(epoch + 1, num_epochs, train_loss, test_loss, train_auc, test_auc))\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['test_loss'].append(test_loss)\n",
    "        #history['train_acc'].append(train_acc)\n",
    "        #history['test_acc'].append(test_acc)\n",
    "        history['train_auc'].append(train_auc)\n",
    "        history['test_auc'].append(test_auc)\n",
    "\n",
    "    fold_perf['fold{}'.format(fold+1)] = history  \n",
    "\n",
    "    torch.save(model,f'baseline_logit_ll_{fold+1}th_fold_{k}_folds_cross_kn_label_imputation.pt')\n",
    "\n",
    "# Move over working experiment to a different script\n",
    "# This includes:\n",
    "#  1) Data processing\n",
    "#  2) Model Declaration/Definition\n",
    "#  3) Loss Function Code\n",
    "#  4) Optimizer Declaration\n",
    "#  5) Training and Validation Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = SubsetRandomSampler([i for i in range(len(dset_test))])\n",
    "\n",
    "test_test_loader = DataLoader(dset_test, batch_size=batch_size, sampler=sampler)\n",
    "model_a = torch.load('baseline_1th_fold_4_folds_cross_kn_label_imputation.pt')\n",
    "model_b = torch.load('baseline_2th_fold_4_folds_cross_kn_label_imputation.pt')\n",
    "model_c = torch.load('baseline_3th_fold_4_folds_cross_kn_label_imputation.pt')\n",
    "model_d = torch.load('baseline_4th_fold_4_folds_cross_kn_label_imputation.pt')\n",
    "model_a.eval()\n",
    "model_b.eval()\n",
    "model_c.eval()\n",
    "model_d.eval()\n",
    "\n",
    "models = [model_a, model_b, model_c, model_d]\n",
    "\n",
    "def test_detection(models,device,dataloader):\n",
    "    total_scores = []\n",
    "    total_labels = []\n",
    "\n",
    "    for images, labels in dataloader:\n",
    "\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        labels = torch.tensor([1 if label == 0 else 0 for label in labels])\n",
    "        outputs = []\n",
    "\n",
    "        for model in models:\n",
    "            outputs.append(model(images))\n",
    "\n",
    "        sum = torch.zeros_like(outputs[0])\n",
    "\n",
    "        for output in outputs:\n",
    "            sum += output\n",
    "\n",
    "        avg_logits = sum / len(outputs)\n",
    "\n",
    "        scores, _ = torch.max(-1*avg_logits.data, 1)\n",
    "\n",
    "        total_scores = total_scores + [i for i in scores]\n",
    "        total_labels = total_labels + [i for i in labels]\n",
    "\n",
    "    total_scores = torch.tensor(total_scores)\n",
    "    total_labels = torch.tensor(total_labels)\n",
    "    y_true  = torch.reshape(total_labels, total_scores.shape)\n",
    "    y_score = total_scores\n",
    "    val_auc = roc_auc_score(y_true, y_score)\n",
    "\n",
    "    return val_auc\n",
    "\n",
    "test_auc = test_detection(models, device, test_test_loader)\n",
    "print(test_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiclass (Oracle) Helper Functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "num_known_classes = 4\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_nom_dataset  = torch.load('s_X_train_nom_dataset.pt')\n",
    "train_anom_dataset = torch.load('s_X_train_anom_dataset.pt')\n",
    "test_anom_dataset  = torch.load('s_X_test_anom_dataset.pt')\n",
    "test_nom_dataset   = torch.load('s_X_test_nom_dataset.pt')\n",
    "\n",
    "dset1 = train_anom_dataset\n",
    "dset2X, dset2y = test_nom_dataset[0:len(dset1)]\n",
    "dset2 = torch.utils.data.TensorDataset(dset2X, dset2y)\n",
    "dset3 = train_nom_dataset\n",
    "\n",
    "dset = torch.utils.data.ConcatDataset([dset1, dset2, dset3])\n",
    "\n",
    "dset_test1X, dset_test1y = test_nom_dataset[len(dset1):]\n",
    "dset_test1 = torch.utils.data.TensorDataset(dset_test1X, dset_test1y)\n",
    "dset_test2 = test_anom_dataset\n",
    "\n",
    "dset_test = torch.utils.data.ConcatDataset([dset_test1, dset_test2])\n",
    "\n",
    "train_dataloader   = \\\n",
    "        torch.utils.data.DataLoader(\n",
    "            dset,\n",
    "            batch_size = batch_size,\n",
    "            shuffle = True,\n",
    "            num_workers = 8\n",
    "        )\n",
    "\n",
    "test_dataloader   = \\\n",
    "        torch.utils.data.DataLoader(\n",
    "            dset_test,\n",
    "            batch_size = batch_size,\n",
    "            shuffle = True,\n",
    "            num_workers = 8\n",
    "        )\n",
    "\n",
    "\n",
    "# Transfer learning\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, num_known_classes)\n",
    "model.to(device)\n",
    "\n",
    "#print(model(next(iter(train_dataloader))[0].to(device)).shape)\n",
    "\n",
    "m = torch.nn.Softmax(dim=1)\n",
    "one_hot = torch.nn.functional.one_hot\n",
    "\n",
    "alpha=0.1\n",
    "num_epochs = 100\n",
    "k = 4\n",
    "splits = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "fold_perf = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Writing DONE. Debugging IN PROGRESS\n",
    "def train_epoch(model,device,dataloader,novel_loss,known_loss,optimizer):\n",
    "    train_loss,train_correct=0.0,0\n",
    "    model.train()\n",
    "    for images, labels in dataloader:\n",
    "        #images,labels = images.to(device),labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        novel_idx = torch.tensor([i for i in range(len(labels)) if labels[i] == 0])\n",
    "        nom_idx = torch.tensor([i for i in range(len(labels)) if labels[i] != 0])\n",
    "        novel_images = images[novel_idx.long(),:]\n",
    "        novel_y = labels[novel_idx.long()]\n",
    "        nom_images = images[nom_idx.long(),:]\n",
    "        nom_y = labels[nom_idx.long()]\n",
    "\n",
    "        if novel_images.shape[0] != 0:\n",
    "            novel_images = novel_images.to(device)\n",
    "\n",
    "        nom_images   = nom_images.to(device)\n",
    "\n",
    "        # Keep this line uncommented for detection feedback\n",
    "        # nom_y = torch.zeros_like(nom_y)\n",
    "\n",
    "        # Feed forward\n",
    "        if novel_images.shape[0] != 0:\n",
    "            novel_output = m(model(novel_images))\n",
    "        nom_output = m(model(nom_images))\n",
    "        \n",
    "        # Keep this line uncommented for detection feedback\n",
    "        # nom_y_orig = nom_y\n",
    "        # nom_y = torch.argmax(nom_output, dim=1)\n",
    "\n",
    "        # If the instance is anomalous, use uniform labeling\n",
    "        # NOTE: label matrix is (batch_size x num_nominal_classes)\n",
    "        novel_y_orig = novel_y\n",
    "        novel_y = (1/num_known_classes)*torch.ones((len(novel_y),num_known_classes))\n",
    "\n",
    "        # Converting the nominal labels to be one-hot. Note that these\n",
    "        # will be label-smoothed when loss is computed.\n",
    "        nom_y_orig = convert_to_model_labels(nom_y) # UNCOMMENT FOR MULTICLASS FEEDBACK\n",
    "        nom_y = torch.squeeze(one_hot(nom_y_orig, num_known_classes).float())\n",
    "\n",
    "        if novel_images.shape[0] != 0:\n",
    "            novel_y = novel_y.to(device)\n",
    "        nom_y = nom_y.to(device)\n",
    "\n",
    "        if novel_images.shape[0] != 0:\n",
    "            loss = novel_loss(novel_output, novel_y) \\\n",
    "                    + known_loss(nom_output, nom_y)\n",
    "        else:\n",
    "            loss = known_loss(nom_output, nom_y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "\n",
    "        if novel_images.shape[0] != 0:\n",
    "            novel_scores, novel_predictions = torch.max(novel_output.data, 1)\n",
    "\n",
    "        nom_scores, nom_predictions = torch.max(nom_output.data, 1)\n",
    "\n",
    "        # print(nom_predictions.shape)\n",
    "        # print(nom_y_orig.shape)\n",
    "\n",
    "        if novel_images.shape[0] != 0:\n",
    "            # print(novel_predictions.shape)\n",
    "            # print(novel_y_orig.shape)\n",
    "            train_correct += (novel_predictions == torch.squeeze(novel_y_orig).to(device)).sum().item()\n",
    "\n",
    "        train_correct += (nom_predictions == torch.squeeze(nom_y_orig).to(device)).sum().item()\n",
    "\n",
    "    return train_loss,train_correct\n",
    "\n",
    "# TODO: Writing DONE. Debugging IN PROGRESS\n",
    "def valid_epoch(model,device,dataloader,novel_loss,known_loss):\n",
    "    valid_loss, val_correct = 0.0, 0\n",
    "    model.eval()\n",
    "    for images, labels in dataloader:\n",
    "\n",
    "        images,labels = images.to(device),labels.to(device)\n",
    "\n",
    "        novel_idx = torch.tensor([i for i in range(len(labels)) if labels[i] == 0])\n",
    "        nom_idx = torch.tensor([i for i in range(len(labels)) if labels[i] != 0])\n",
    "        novel_images = images[novel_idx.long(),:]\n",
    "        novel_y = labels[novel_idx.long()]\n",
    "        nom_images = images[nom_idx.long(),:]\n",
    "        nom_y = labels[nom_idx.long()]\n",
    "\n",
    "        nom_images   = nom_images.to(device)\n",
    "\n",
    "        # Keep this line uncommented for detection feedback\n",
    "        # nom_y = torch.zeros_like(nom_y)\n",
    "\n",
    "        # Feed forward\n",
    "        if novel_images.shape[0] != 0:\n",
    "            novel_output = m(model(novel_images))\n",
    "        nom_output = m(model(nom_images))\n",
    "        \n",
    "        # Keep this line uncommented for detection feedback\n",
    "        # nom_y_orig = nom_y\n",
    "        # nom_y = torch.argmax(nom_output, dim=1)\n",
    "\n",
    "        # If the instance is anomalous, use uniform labeling\n",
    "        # NOTE: label matrix is (batch_size x num_nominal_classes)\n",
    "        novel_y_orig = novel_y\n",
    "        novel_y = (1/num_known_classes)*torch.ones((len(novel_y),num_known_classes))\n",
    "\n",
    "        # Converting the nominal labels to be one-hot. Note that these\n",
    "        # will be label-smoothed when loss is computed\n",
    "        nom_y_orig = convert_to_model_labels(nom_y) # UNCOMMENT FOR MULTICLASS FEEDBACK\n",
    "        nom_y = torch.squeeze(one_hot(nom_y_orig, num_known_classes).float())\n",
    "\n",
    "        if novel_images.shape[0] != 0:\n",
    "            novel_y = novel_y.to(device)\n",
    "        nom_y = nom_y.to(device)\n",
    "\n",
    "        if novel_images.shape[0] != 0:\n",
    "            loss = novel_loss(novel_output, novel_y) \\\n",
    "                    + known_loss(nom_output, nom_y)\n",
    "        else:\n",
    "            loss = known_loss(nom_output, nom_y)\n",
    "\n",
    "        valid_loss+=loss.item()*images.size(0)\n",
    "\n",
    "        if novel_images.shape[0] != 0:\n",
    "            novel_scores, novel_predictions = torch.max(novel_output.data, 1)\n",
    "            \n",
    "        nom_scores, nom_predictions = torch.max(nom_output.data, 1)\n",
    "        \n",
    "        if novel_images.shape[0] != 0:\n",
    "            val_correct += (novel_predictions == torch.squeeze(novel_y_orig).to(device)).sum().item()\n",
    "\n",
    "        val_correct += (nom_predictions == torch.squeeze(nom_y_orig).to(device)).sum().item()\n",
    "\n",
    "    return valid_loss,val_correct\n",
    "\n",
    "def convert_to_model_labels(nom_labels):\n",
    "    return nom_labels - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novel_loss = nn.CrossEntropyLoss()\n",
    "known_loss = nn.CrossEntropyLoss() #label_smoothing=alpha) # Don't use label smoothing for known_loss unless you're performing detection feedback experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(dset)))):\n",
    "\n",
    "    print('Fold {}'.format(fold + 1))\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(val_idx)\n",
    "    train_loader = DataLoader(dset, batch_size=batch_size, sampler=train_sampler)\n",
    "    test_loader = DataLoader(dset, batch_size=batch_size, sampler=test_sampler)\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, num_known_classes)\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
    "\n",
    "    history = {'train_loss': [], 'test_loss': [],'train_acc':[],'test_acc':[]}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_correct=train_epoch(model,device,train_loader,novel_loss,known_loss,optimizer)\n",
    "        with torch.no_grad():\n",
    "            test_loss, test_correct=valid_epoch(model,device,test_loader,novel_loss,known_loss)\n",
    "\n",
    "        print(train_correct)\n",
    "        print(len(train_loader.sampler))\n",
    "\n",
    "        train_loss = train_loss / len(train_loader.sampler)\n",
    "        train_acc = train_correct / len(train_loader.sampler) * 100\n",
    "        test_loss = test_loss / len(test_loader.sampler)\n",
    "        test_acc = test_correct / len(test_loader.sampler) * 100\n",
    "\n",
    "        print(\"Epoch:{}/{} AVG Training Loss:{:.3f} AVG Test Loss:{:.3f} AVG Training Acc {:.2f} % AVG Test Acc {:.2f} %\".format(epoch + 1,\n",
    "                                                                                                             num_epochs,\n",
    "                                                                                                             train_loss,\n",
    "                                                                                                             test_loss,\n",
    "                                                                                                             train_acc,\n",
    "                                                                                                             test_acc))\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['test_loss'].append(test_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['test_acc'].append(test_acc)\n",
    "\n",
    "    fold_perf['fold{}'.format(fold+1)] = history  \n",
    "\n",
    "    torch.save(model,f'baseline_{fold+1}th_fold_{k}_folds_cross_kn_label_imputation.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['fold1', 'fold2', 'fold3', 'fold4'])\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "folds_copy = copy.deepcopy(fold_perf)\n",
    "print(folds_copy.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train_loss', 'test_loss', 'train_acc', 'test_acc', 'train_auc', 'test_auc'])\n"
     ]
    }
   ],
   "source": [
    "print(folds_copy['fold1'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def average_entries(data_dict, key):\n",
    "    meta_keys = list(data_dict.keys())\n",
    "    num_folds = len(meta_keys)\n",
    "    assert(len(meta_keys) > 0)\n",
    "    keys = list(data_dict[meta_keys[0]].keys())\n",
    "    assert(len(keys) > 0)\n",
    "    num_entries = len(data_dict[meta_keys[0]][keys[0]])\n",
    "\n",
    "    avg_data = []\n",
    "    for i in range(num_entries):\n",
    "        sum = 0\n",
    "        for fold in meta_keys:\n",
    "            sum += data_dict[fold][key][i]\n",
    "        avg_data.append(sum/num_folds)\n",
    "\n",
    "    return avg_data\n",
    "\n",
    "\n",
    "avgs = {}\n",
    "avgs['train_loss'] = average_entries(folds_copy, 'train_loss')\n",
    "avgs['test_loss']  = average_entries(folds_copy, 'test_loss')\n",
    "# avgs['train_acc']  = average_entries(folds_copy, 'train_acc')\n",
    "# avgs['test_acc']   = average_entries(folds_copy, 'test_acc')\n",
    "avgs['train_auc'] = average_entries(folds_copy, 'train_auc')\n",
    "avgs['test_auc']  = average_entries(folds_copy, 'test_auc')\n",
    "\n",
    "plt.plot(avgs['train_auc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(folds_copy.keys()))\n",
    "keylist = list(folds_copy.keys())\n",
    "print(folds_copy[keylist[0]])\n",
    "print(keylist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(8,6))\n",
    "epochs = [i for i in range(1,101)]\n",
    "print(epochs)\n",
    "\n",
    "fig.suptitle('Avg Baseline Train CE, FB known imputed, OE (4-Fold CV)', fontsize=15)\n",
    "\n",
    "ax.plot(epochs, avgs['train_loss'], label='Train Loss')\n",
    "ax.plot(epochs, avgs['test_loss'], label='Test Loss')\n",
    "# # ax.plot(epochs, avgs['train_acc'], label='Train Accuracy')\n",
    "# # ax.plot(epochs, avgs['test_acc'], label='Test Accuracy')\n",
    "\n",
    "# ax.plot(epochs, avgs['train_auc'], label='Train AUC')\n",
    "# ax.plot(epochs, avgs['test_auc'], label='Test AUC')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "torch.save(avgs, 'osu_training_known_ce_osu_feedback_known_imputation_novel_uniform_nft_ll.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting Test AUCs across all of these experiments\n",
    "f1 = 'osu_training_known_ce_nft_ll.pt'\n",
    "f2 = 'osu_training_known_ce_osu_feedback_novel_uniform_ce_nft_ll.pt'\n",
    "f3 = 'osu_training_known_ce_osu_feedback_known_ce_nft_ll.pt'\n",
    "f4 = 'osu_training_known_ce_osu_feedback_known_label_imputation_nft_ll.pt'\n",
    "f5 = 'osu_training_known_ce_osu_feedback_known_imputation_novel_uniform_nft_ll.pt'\n",
    "file_handles = [f1, f2, f3, f4, f5]\n",
    "\n",
    "collected_avgs = []\n",
    "\n",
    "for f in file_handles:\n",
    "    collected_avgs.append(torch.load(f))\n",
    "\n",
    "max_x = 30 #len(collected_avgs[0]['test_auc'])\n",
    "assert(max_x <= len(collected_avgs[0]['test_auc']) and max_x > 0)\n",
    "x = [i for i in range(max_x)]\n",
    "\n",
    "# Plotting\n",
    "for i, avgs in enumerate(collected_avgs):\n",
    "    plt.plot(x, avgs['test_auc'][0:max_x], label=f'11bi{i+1}')\n",
    "\n",
    "plt.title('Averaged Test AUCs for Baselines')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Test AUC')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Margin Loss Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "num_known_classes = 4\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_nom_dataset  = torch.load('s_X_train_nom_dataset.pt')\n",
    "train_anom_dataset = torch.load('s_X_train_anom_dataset.pt')\n",
    "test_anom_dataset  = torch.load('s_X_test_anom_dataset.pt')\n",
    "test_nom_dataset   = torch.load('s_X_test_nom_dataset.pt')\n",
    "\n",
    "dset1 = train_anom_dataset\n",
    "dset2X, dset2y = test_nom_dataset[0:len(dset1)]\n",
    "dset2 = torch.utils.data.TensorDataset(dset2X, dset2y)\n",
    "dset3 = train_nom_dataset\n",
    "\n",
    "dset = torch.utils.data.ConcatDataset([dset1, dset2, dset3])\n",
    "\n",
    "dset_test1X, dset_test1y = test_nom_dataset[len(dset1):]\n",
    "dset_test1 = torch.utils.data.TensorDataset(dset_test1X, dset_test1y)\n",
    "dset_test2 = test_anom_dataset\n",
    "\n",
    "dset_test = torch.utils.data.ConcatDataset([dset_test1, dset_test2])\n",
    "\n",
    "train_dataloader   = \\\n",
    "        torch.utils.data.DataLoader(\n",
    "            train_nom_dataset,\n",
    "            batch_size = batch_size,\n",
    "            shuffle = True,\n",
    "            num_workers = 8\n",
    "        )\n",
    "\n",
    "test_dataloader   = \\\n",
    "        torch.utils.data.DataLoader(\n",
    "            train_nom_dataset,\n",
    "            batch_size = batch_size,\n",
    "            shuffle = True,\n",
    "            num_workers = 8\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomalyMarginLoss(outputs, labels, tau=0.5, mu=0.2):\n",
    "    ''' \n",
    "    Score A(x_q) = -max_k \\sum_{j=1}^d w_{kj} z_{qj} \n",
    "    \n",
    "    k: class\n",
    "    q: query number\n",
    "    j: feature number\n",
    "    \n",
    "    L(W) = max(0, [A(x_i) - (\\tao + \\mu n_i)(-n_i)])\n",
    "\n",
    "    where n_i is the label corresponding to example i:\n",
    "\n",
    "    +1: novel\n",
    "    -1: nominal\n",
    "    \n",
    "    Args:\n",
    "        outputs: A(x_i)\n",
    "        labels:  n_i\n",
    "    '''\n",
    "    adjusted = (outputs-(tau+mu*labels))*(-labels)\n",
    "    instancewise_loss =  torch.maximum(torch.zeros_like(adjusted),adjusted)\n",
    "    return torch.sum(instancewise_loss)\n",
    "\n",
    "\n",
    "class AnomalyFC(nn.Module):\n",
    "    ''' This will be a single fc layer with no activation '''\n",
    "    def __init__(self, D_in, D_out):\n",
    "        super(AnomalyFC, self).__init__()\n",
    "        self.linear = nn.Linear(D_in, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Computing the logits\n",
    "        x = self.linear(x)\n",
    "\n",
    "        # And, finally, an anomaly score\n",
    "        x = -(torch.max(x,1)[0])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "\n",
    "bottleneck_dim = 256\n",
    "num_subject_classes = 5\n",
    "\n",
    "state_dicts = torch.load(f'new_subject_classifier.pth')\n",
    "\n",
    "feature_extractor = resnet18(pretrained=True)\n",
    "feature_extractor.fc = torch.nn.Linear(feature_extractor.fc.weight.shape[1], bottleneck_dim)\n",
    "subject_classifier = AnomalyFC(bottleneck_dim, num_subject_classes)\n",
    "\n",
    "sc_dict = {}\n",
    "sc_dict['linear.weight'] = state_dicts['classifier']['weight']\n",
    "sc_dict['linear.bias']   = state_dicts['classifier']['bias']\n",
    " \n",
    "feature_extractor.load_state_dict(state_dicts['feature_extractor'])\n",
    "subject_classifier.load_state_dict(sc_dict)\n",
    "\n",
    "feature_extractor.to(device)\n",
    "subject_classifier.to(device)\n",
    "\n",
    "m = torch.nn.Softmax(dim=1)\n",
    "one_hot = torch.nn.functional.one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "torch.manual_seed(0)\n",
    "cudnn.deterministic = True\n",
    "cudnn.benchmark = True\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "alphas = [0.01, 0.03, 0.1, 0.3]\n",
    "learning_rates = [3e-4, 1e-3, 3e-3, 1e-2, 3e-2]\n",
    "tau = -4.9\n",
    "learning_rate = 1e-3\n",
    "alpha = 0.01\n",
    "lambda_l2 = 1e-5\n",
    "batch_size = 16\n",
    "mus = [i for i in range(0,5)]\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "num_known_classes = 4\n",
    "\n",
    "train_nom_dataset  = torch.load('s_z_train_nom_dataset.pt')\n",
    "train_anom_dataset = torch.load('s_z_train_anom_dataset.pt')\n",
    "test_anom_dataset  = torch.load('s_z_test_anom_dataset.pt')\n",
    "test_nom_dataset   = torch.load('s_z_test_nom_dataset.pt')\n",
    "\n",
    "train_anom_dataloader = \\\n",
    "        torch.utils.data.DataLoader(\n",
    "            train_anom_dataset,\n",
    "            batch_size = batch_size,\n",
    "            shuffle = True,\n",
    "            num_workers = 0\n",
    "        )\n",
    "test_nom_dataloader   = \\\n",
    "        torch.utils.data.DataLoader(\n",
    "            test_nom_dataset,\n",
    "            batch_size = batch_size,\n",
    "            shuffle = True,\n",
    "            num_workers = 0\n",
    "        )\n",
    "\n",
    "optimizer = torch.optim.SGD(subject_classifier.parameters(), lr=learning_rate, weight_decay=lambda_l2)\n",
    "\n",
    "m = torch.nn.Softmax(dim=1)\n",
    "one_hot = torch.nn.functional.one_hot\n",
    "\n",
    "subject_classifier.train()\n",
    "subject_classifier.to(device)\n",
    "\n",
    "# Since there are only 73 examples in train_anom, this should only utilize\n",
    "# 73 of the known in instances in the test set, leaving the rest for testing.\n",
    "# There are 721 nominal examples in the test nom set total.\n",
    "\n",
    "losses = []\n",
    "lr_losses = []\n",
    "alpha_losses = []\n",
    "mu_losses = []\n",
    "num_batches = len(train_anom_dataset) // batch_size\n",
    "mu_accuracies = []\n",
    "mu_aucs = []\n",
    "\n",
    "#optimizer = torch.optim.SGD(subject_classifier.parameters(), lr=lr, weight_decay=lambda_l2)\n",
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "feature_extractor = resnet18(pretrained=True)\n",
    "feature_extractor.fc = torch.nn.Linear(feature_extractor.fc.weight.shape[1], bottleneck_dim)\n",
    "subject_classifier = AnomalyFC(bottleneck_dim, num_subject_classes)\n",
    "\n",
    "sc_dict = {}\n",
    "sc_dict['linear.weight'] = state_dicts['classifier']['weight']\n",
    "sc_dict['linear.bias']   = state_dicts['classifier']['bias']\n",
    "\n",
    "feature_extractor.load_state_dict(state_dicts['feature_extractor'])\n",
    "subject_classifier.load_state_dict(sc_dict)\n",
    "\n",
    "feature_extractor.to(device)\n",
    "subject_classifier.to(device)\n",
    "\n",
    "for mu in mus:\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    aucs = []\n",
    "    for i in range(num_epochs):\n",
    "        correct = 0\n",
    "        total   = 0\n",
    "        scores = []\n",
    "        labels_arr = []\n",
    "        for j, ((anom_X, anom_y), (nom_X, nom_y)) in enumerate(zip(train_anom_dataloader, test_nom_dataloader)):\n",
    "\n",
    "            anom_X = anom_X.to(device)\n",
    "            nom_X  = nom_X.to(device)\n",
    "            anom_y = anom_y.to(device)\n",
    "            nom_y = nom_y.to(device)\n",
    "\n",
    "            # Feed forward\n",
    "            anom_predictions = subject_classifier(anom_X)\n",
    "            nom_predictions  = subject_classifier(nom_X)\n",
    "\n",
    "            outputs = torch.hstack((nom_predictions, anom_predictions))\n",
    "            labels  = torch.hstack((torch.zeros_like(nom_predictions), torch.ones_like(anom_predictions)))\n",
    "\n",
    "            # Compute loss. Note that arguments are (input, target).\n",
    "            #\n",
    "            # Input needs to be (batch_size x num_classes).\n",
    "            # Target needs to be same shape as input since it contains class\n",
    "            # probabilities.\n",
    "            loss = anomalyMarginLoss(outputs, labels, tau=tau, mu=mu)\n",
    "            # losses.append(loss)\n",
    "\n",
    "            # Zero the optimizer's gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Backpropagate to compute the gradients\n",
    "            # of the loss with respect to our learnable\n",
    "            # parameters\n",
    "            loss.backward()\n",
    "\n",
    "            correct += ((outputs > tau) == torch.squeeze(labels).to(device)).sum().item()\n",
    "            total += anom_X.shape[0] + nom_X.shape[0]\n",
    "\n",
    "            # Update the learnable parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            scores = scores + [i for i in anom_predictions]\n",
    "            scores = scores + [i for i in nom_predictions]\n",
    "            labels_arr = labels_arr + [i for i in labels]\n",
    "\n",
    "        scores = torch.tensor(scores)\n",
    "        labels_arr = torch.tensor(labels_arr)\n",
    "        auc = roc_auc_score(labels_arr, scores)\n",
    "\n",
    "        losses.append(loss)\n",
    "        accuracies.append(correct / total)\n",
    "        aucs.append(auc)\n",
    "        print(f'mu={mu} epoch={i+1}/{num_epochs} loss={loss} accuracy={correct / total} auc={auc}')\n",
    "\n",
    "    mu_accuracies.append(accuracies)\n",
    "    mu_losses.append(losses)\n",
    "    mu_aucs.append(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "batches = np.arange(0,len(losses))\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(8,6))\n",
    "\n",
    "fig.suptitle('Mu Sweep', fontsize=15)\n",
    "\n",
    "for i, mu in enumerate(mus):\n",
    "    ax.plot(batches, mu_aucs[i], label=f'mu={mu}')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('AUC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "668ea60db213cab2c994592c1f393238bcd53acb6415f24ace7b3e4acf2d61d5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('osr': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
