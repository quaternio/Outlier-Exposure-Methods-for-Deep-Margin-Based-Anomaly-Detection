{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "\n",
    "import torch\n",
    "device = torch.device(\"cuda\")\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet34, resnet50\n",
    "from torchvision.models.feature_extraction import get_graph_node_names\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from torch.utils import data\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, SGD, RMSprop\n",
    "from torchvision.models import resnet34, resnet50\n",
    "import numpy as np\n",
    "from large_margin import LargeMarginLoss\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "def _init_resnet_50(output_size, pretrained = False, features_hook = None):\n",
    "    model = resnet50(pretrained=pretrained)\n",
    "    model.fc = torch.nn.Linear(2048, output_size)\n",
    "    if features_hook is not None:\n",
    "        for name, module in model.named_modules():\n",
    "            if name in ['layer1', 'layer2', 'layer3', 'layer4']:\n",
    "                module.register_forward_hook(features_hook)\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_pretrained_model(architecture, n_classes, features_hook = None):\n",
    "    pretrained = True\n",
    "    if 'resnet50' in architecture:\n",
    "        net = _init_resnet_50(n_classes, pretrained, features_hook)\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    return net\n",
    "    \n",
    "def create_model(architecture, n_classes, features_hook = None):\n",
    "    pretrained = False\n",
    "    if 'resnet50' in architecture:\n",
    "        net = _init_resnet_50(n_classes, pretrained, features_hook)\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    return net\n",
    "\n",
    "class FeatureExtractor(torch.nn.Module):\n",
    "    def __init__(self, architecture, n_classes = None):\n",
    "        super().__init__()\n",
    "        self._features = []\n",
    "        if 'pretrained' in architecture:\n",
    "            self.model = create_pretrained_model(\n",
    "                architecture, \n",
    "                n_classes, \n",
    "                features_hook=self.feature_hook)\n",
    "        else:\n",
    "            self.model = create_model(\n",
    "                architecture, \n",
    "                n_classes, \n",
    "                features_hook=self.feature_hook)\n",
    "\n",
    "    def feature_hook(self, module, input, output):\n",
    "        self._features.append(output[0])\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.model(x)\n",
    "        return logits, self._features\n",
    "\n",
    "my_module = FeatureExtractor('resnet50', 100)\n",
    "\n",
    "train_loader = data.DataLoader(\n",
    "        datasets.CIFAR100('./data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229, 0.224, 0.225])\n",
    "                       ])),\n",
    "        batch_size=256, shuffle=True, drop_last=True)\n",
    "\n",
    "lm = LargeMarginLoss(\n",
    "    gamma=10000,\n",
    "    alpha_factor=4,\n",
    "    top_k=1,\n",
    "    dist_norm=np.inf\n",
    ")\n",
    "\n",
    "net = FeatureExtractor('resnet50', 100)\n",
    "net.to(device)\n",
    "\n",
    "layer_1_output = None\n",
    "def forward_hook_1(module, input, output):\n",
    "    global layer_1_output\n",
    "    layer_1_output = output\n",
    "\n",
    "net.model.layer1.register_forward_hook(forward_hook_1)\n",
    "\n",
    "layer_2_output = None\n",
    "def forward_hook_2(module, input, output):\n",
    "    global layer_2_output\n",
    "    layer_2_output = output\n",
    "\n",
    "net.model.layer2.register_forward_hook(forward_hook_2)\n",
    "\n",
    "layer_3_output = None\n",
    "def forward_hook_3(module, input, output):\n",
    "    global layer_3_output\n",
    "    layer_3_output = output\n",
    "\n",
    "net.model.layer3.register_forward_hook(forward_hook_3)\n",
    "\n",
    "layer_4_output = None\n",
    "def forward_hook_4(module, input, output):\n",
    "    global layer_4_output\n",
    "    layer_4_output = output\n",
    "\n",
    "net.model.layer4.register_forward_hook(forward_hook_4)\n",
    "\n",
    "X = torch.randn(256, 3, 32, 32)\n",
    "out, features = net(X.to(device))\n",
    "one_hot = F.one_hot(torch.arange(0,256) % 100)\n",
    "\n",
    "one_hot = one_hot.to(device)\n",
    "\n",
    "top_k = 1\n",
    "\n",
    "prob = F.softmax(out, dim=1)\n",
    "correct_prob = prob * one_hot\n",
    "\n",
    "correct_prob = torch.sum(correct_prob, dim=1, keepdim=True)\n",
    "other_prob = prob * (1.0 - one_hot)\n",
    "\n",
    "if top_k > 1:\n",
    "    topk_prob, _ = other_prob.topk(top_k, dim=1)\n",
    "else:\n",
    "    topk_prob, _ = other_prob.max(dim=1, keepdim=True)\n",
    "\n",
    "diff_prob = correct_prob - topk_prob\n",
    "\n",
    "loss = torch.empty(0, device=out.device)\n",
    "\n",
    "for feature_map in [layer_1_output, layer_2_output, layer_3_output, layer_4_output]:\n",
    "    for i in range(top_k):\n",
    "        torch.autograd.grad(diff_prob[:,i], feature_map,\n",
    "            grad_outputs=torch.ones_like(diff_prob[:,i], dtype=torch.float32),\n",
    "            retain_graph=True)\n",
    "            \n",
    "    #diff_grad = torch.stack([_get_grad(diff_prob[:, i], feature_map) for i in range(top_k)],\n",
    "    #                        dim=1)\n",
    "\n",
    "# logits, onehot_labels, feature_maps\n",
    "# loss = lm(out, one_hot.to(device), features)\n",
    "\n",
    "# grad1 = torch.autograd.grad(out, layer_1_output, grad_outputs=torch.ones_like(out), retain_graph=True)\n",
    "# grad2 = torch.autograd.grad(out, layer_2_output, grad_outputs=torch.ones_like(out), retain_graph=True)\n",
    "# grad3 = torch.autograd.grad(out, layer_3_output, grad_outputs=torch.ones_like(out), retain_graph=True)\n",
    "# grad4 = torch.autograd.grad(out, layer_4_output, grad_outputs=torch.ones_like(out), retain_graph=True)\n",
    "\n",
    "# print(grad4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c4398fe4326ca2b310b1f568ae2edc0d6beeed283627d7603b214c23f7002199"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 ('project': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
