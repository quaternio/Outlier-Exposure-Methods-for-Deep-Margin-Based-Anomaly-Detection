{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtnoel20\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "/nfs/stak/users/noelt/Documents/Project/Large_Margin_Loss_PyTorch-master/envs/project/lib64/python3.6/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/stak/users/noelt/Documents/Project/Large_Margin_Loss_PyTorch-master/wandb/run-20220706_172625-23kjczpd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/tnoel20/Thomas-Masters-Project/runs/23kjczpd\" target=\"_blank\">unique-resonance-34</a></strong> to <a href=\"https://wandb.ai/tnoel20/Thomas-Masters-Project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "\n",
    "import torch\n",
    "device = torch.device(\"cuda\")\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "from torchvision.models import resnet34, resnet50\n",
    "from torchvision.models.feature_extraction import get_graph_node_names\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "\n",
    "# Setup Weights and Biases and specify hyperparameters\n",
    "wandb.init(project=\"Thomas-Masters-Project\")\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs = 5\n",
    "batch_size = 256\n",
    "net_type = \"pretrained_resnet50\"\n",
    "\n",
    "wandb.config = {\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"epochs\": epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"network\": net_type\n",
    "}\n",
    "\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad(): \n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output, *_ = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            _, idx = output.max(dim=1)\n",
    "            correct += (idx == target).sum().item()\n",
    "\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print('Test set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(test_loader.dataset), accuracy))\n",
    "\n",
    "    wandb.log({\"accuracy\": accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_resnet_50(output_size, pretrained = False, features_hook = None):\n",
    "    model = resnet50(pretrained=pretrained)\n",
    "    model.fc = torch.nn.Linear(2048, output_size)\n",
    "    if features_hook is not None:\n",
    "        for name, module in model.named_modules():\n",
    "            if name in ['layer1', 'layer2', 'layer3', 'layer4']:\n",
    "                module.register_forward_hook(features_hook)\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_pretrained_model(architecture, n_classes, features_hook = None):\n",
    "    pretrained = True\n",
    "    if 'resnet50' in architecture:\n",
    "        net = _init_resnet_50(n_classes, pretrained, features_hook)\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    return net\n",
    "    \n",
    "def create_model(architecture, n_classes, features_hook = None):\n",
    "    pretrained = False\n",
    "    if 'resnet50' in architecture:\n",
    "        net = _init_resnet_50(n_classes, pretrained, features_hook)\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    return net\n",
    "\n",
    "class FeatureExtractor(torch.nn.Module):\n",
    "    def __init__(self, architecture, n_classes = None):\n",
    "        super().__init__()\n",
    "        self._features = []\n",
    "        if 'pretrained' in architecture:\n",
    "            self.model = create_pretrained_model(\n",
    "                architecture, \n",
    "                n_classes, \n",
    "                features_hook=self.feature_hook)\n",
    "        else:\n",
    "            self.model = create_model(\n",
    "                architecture, \n",
    "                n_classes, \n",
    "                features_hook=self.feature_hook)\n",
    "\n",
    "    def feature_hook(self, module, input, output):\n",
    "        self._features.append(output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.model(x)\n",
    "        return logits, self._features\n",
    "\n",
    "    def clear_features(self):\n",
    "        self._features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torch.utils import data\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, SGD, RMSprop\n",
    "\n",
    "train_loader = data.DataLoader(\n",
    "        datasets.CIFAR100('./data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229, 0.224, 0.225])\n",
    "                       ])),\n",
    "        batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "test_loader = data.DataLoader(\n",
    "        datasets.CIFAR100('./data', train=False,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229, 0.224, 0.225])\n",
    "                       ])),\n",
    "        batch_size=2048, shuffle=False, drop_last=False)\n",
    "\n",
    "num_training_classes = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/50000 (0%)]\tLoss: 0.000062\n",
      "Train Epoch: 0 [25600/50000 (51%)]\tLoss: -178.250946\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from large_margin import LargeMarginLoss\n",
    "\n",
    "\n",
    "lm = LargeMarginLoss(\n",
    "    gamma=10000,\n",
    "    alpha_factor=4,\n",
    "    top_k=num_training_classes,\n",
    "    dist_norm=np.inf\n",
    ")\n",
    "\n",
    "net = FeatureExtractor(net_type, num_training_classes)\n",
    "net.to(device)\n",
    "\n",
    "def train_lm(model, train_loader, optimizer, epoch, lm):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        one_hot = torch.zeros(len(target), 100).scatter_(1, target.unsqueeze(1), 1.).float()\n",
    "        one_hot = one_hot.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output, features = model(data)\n",
    "        model.clear_features()\n",
    "\n",
    "        loss = lm(output, one_hot, features)\n",
    "        \n",
    "        wandb.log({\"loss\": loss})\n",
    "        # optional\n",
    "        wandb.watch(model)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def convert_feature_map_to_list(feature_map):\n",
    "    num_feature_layers = len(feature_map)\n",
    "    feature_list = []\n",
    "    for i in range(num_feature_layers):\n",
    "        feature_list.append(feature_map['layer{}'.format(i+1)])\n",
    "    \n",
    "    return feature_list\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "optim = Adam(net.parameters()) #SGD(net.parameters(), lr=learning_rate, momentum=0)\n",
    "for i in range(0, epochs):\n",
    "    start_time = time.time()\n",
    "    train_lm(net, train_loader, optim, i, lm)\n",
    "    end_time = time.time()\n",
    "\n",
    "    print('Epoch {} took {} seconds to complete'.format(i+1, end_time-start_time))\n",
    "\n",
    "    test(net, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ce(model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output, _ = model(data)\n",
    "        model.clear_features()\n",
    "\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "net = net_dict[net_type]().to(device)\n",
    "# net = nn.DataParallel(net).to(device)\n",
    "optim = Adam(net.parameters())\n",
    "for i in range(0, epochs):    \n",
    "    train_ce(net, train_loader, optim, i)\n",
    "    test(net, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "features\n",
      "features.0\n",
      "features.0.0\n",
      "features.0.1\n",
      "features.0.2\n",
      "features.1\n",
      "features.1.0\n",
      "features.1.0.block\n",
      "features.1.0.block.0\n",
      "features.1.0.block.0.0\n",
      "features.1.0.block.0.1\n",
      "features.1.0.block.0.2\n",
      "features.1.0.block.1\n",
      "features.1.0.block.1.avgpool\n",
      "features.1.0.block.1.fc1\n",
      "features.1.0.block.1.fc2\n",
      "features.1.0.block.1.activation\n",
      "features.1.0.block.1.scale_activation\n",
      "features.1.0.block.2\n",
      "features.1.0.block.2.0\n",
      "features.1.0.block.2.1\n",
      "features.1.0.stochastic_depth\n",
      "features.1.1\n",
      "features.1.1.block\n",
      "features.1.1.block.0\n",
      "features.1.1.block.0.0\n",
      "features.1.1.block.0.1\n",
      "features.1.1.block.0.2\n",
      "features.1.1.block.1\n",
      "features.1.1.block.1.avgpool\n",
      "features.1.1.block.1.fc1\n",
      "features.1.1.block.1.fc2\n",
      "features.1.1.block.1.activation\n",
      "features.1.1.block.1.scale_activation\n",
      "features.1.1.block.2\n",
      "features.1.1.block.2.0\n",
      "features.1.1.block.2.1\n",
      "features.1.1.stochastic_depth\n",
      "features.2\n",
      "features.2.0\n",
      "features.2.0.block\n",
      "features.2.0.block.0\n",
      "features.2.0.block.0.0\n",
      "features.2.0.block.0.1\n",
      "features.2.0.block.0.2\n",
      "features.2.0.block.1\n",
      "features.2.0.block.1.0\n",
      "features.2.0.block.1.1\n",
      "features.2.0.block.1.2\n",
      "features.2.0.block.2\n",
      "features.2.0.block.2.avgpool\n",
      "features.2.0.block.2.fc1\n",
      "features.2.0.block.2.fc2\n",
      "features.2.0.block.2.activation\n",
      "features.2.0.block.2.scale_activation\n",
      "features.2.0.block.3\n",
      "features.2.0.block.3.0\n",
      "features.2.0.block.3.1\n",
      "features.2.0.stochastic_depth\n",
      "features.2.1\n",
      "features.2.1.block\n",
      "features.2.1.block.0\n",
      "features.2.1.block.0.0\n",
      "features.2.1.block.0.1\n",
      "features.2.1.block.0.2\n",
      "features.2.1.block.1\n",
      "features.2.1.block.1.0\n",
      "features.2.1.block.1.1\n",
      "features.2.1.block.1.2\n",
      "features.2.1.block.2\n",
      "features.2.1.block.2.avgpool\n",
      "features.2.1.block.2.fc1\n",
      "features.2.1.block.2.fc2\n",
      "features.2.1.block.2.activation\n",
      "features.2.1.block.2.scale_activation\n",
      "features.2.1.block.3\n",
      "features.2.1.block.3.0\n",
      "features.2.1.block.3.1\n",
      "features.2.1.stochastic_depth\n",
      "features.2.2\n",
      "features.2.2.block\n",
      "features.2.2.block.0\n",
      "features.2.2.block.0.0\n",
      "features.2.2.block.0.1\n",
      "features.2.2.block.0.2\n",
      "features.2.2.block.1\n",
      "features.2.2.block.1.0\n",
      "features.2.2.block.1.1\n",
      "features.2.2.block.1.2\n",
      "features.2.2.block.2\n",
      "features.2.2.block.2.avgpool\n",
      "features.2.2.block.2.fc1\n",
      "features.2.2.block.2.fc2\n",
      "features.2.2.block.2.activation\n",
      "features.2.2.block.2.scale_activation\n",
      "features.2.2.block.3\n",
      "features.2.2.block.3.0\n",
      "features.2.2.block.3.1\n",
      "features.2.2.stochastic_depth\n",
      "features.3\n",
      "features.3.0\n",
      "features.3.0.block\n",
      "features.3.0.block.0\n",
      "features.3.0.block.0.0\n",
      "features.3.0.block.0.1\n",
      "features.3.0.block.0.2\n",
      "features.3.0.block.1\n",
      "features.3.0.block.1.0\n",
      "features.3.0.block.1.1\n",
      "features.3.0.block.1.2\n",
      "features.3.0.block.2\n",
      "features.3.0.block.2.avgpool\n",
      "features.3.0.block.2.fc1\n",
      "features.3.0.block.2.fc2\n",
      "features.3.0.block.2.activation\n",
      "features.3.0.block.2.scale_activation\n",
      "features.3.0.block.3\n",
      "features.3.0.block.3.0\n",
      "features.3.0.block.3.1\n",
      "features.3.0.stochastic_depth\n",
      "features.3.1\n",
      "features.3.1.block\n",
      "features.3.1.block.0\n",
      "features.3.1.block.0.0\n",
      "features.3.1.block.0.1\n",
      "features.3.1.block.0.2\n",
      "features.3.1.block.1\n",
      "features.3.1.block.1.0\n",
      "features.3.1.block.1.1\n",
      "features.3.1.block.1.2\n",
      "features.3.1.block.2\n",
      "features.3.1.block.2.avgpool\n",
      "features.3.1.block.2.fc1\n",
      "features.3.1.block.2.fc2\n",
      "features.3.1.block.2.activation\n",
      "features.3.1.block.2.scale_activation\n",
      "features.3.1.block.3\n",
      "features.3.1.block.3.0\n",
      "features.3.1.block.3.1\n",
      "features.3.1.stochastic_depth\n",
      "features.3.2\n",
      "features.3.2.block\n",
      "features.3.2.block.0\n",
      "features.3.2.block.0.0\n",
      "features.3.2.block.0.1\n",
      "features.3.2.block.0.2\n",
      "features.3.2.block.1\n",
      "features.3.2.block.1.0\n",
      "features.3.2.block.1.1\n",
      "features.3.2.block.1.2\n",
      "features.3.2.block.2\n",
      "features.3.2.block.2.avgpool\n",
      "features.3.2.block.2.fc1\n",
      "features.3.2.block.2.fc2\n",
      "features.3.2.block.2.activation\n",
      "features.3.2.block.2.scale_activation\n",
      "features.3.2.block.3\n",
      "features.3.2.block.3.0\n",
      "features.3.2.block.3.1\n",
      "features.3.2.stochastic_depth\n",
      "features.4\n",
      "features.4.0\n",
      "features.4.0.block\n",
      "features.4.0.block.0\n",
      "features.4.0.block.0.0\n",
      "features.4.0.block.0.1\n",
      "features.4.0.block.0.2\n",
      "features.4.0.block.1\n",
      "features.4.0.block.1.0\n",
      "features.4.0.block.1.1\n",
      "features.4.0.block.1.2\n",
      "features.4.0.block.2\n",
      "features.4.0.block.2.avgpool\n",
      "features.4.0.block.2.fc1\n",
      "features.4.0.block.2.fc2\n",
      "features.4.0.block.2.activation\n",
      "features.4.0.block.2.scale_activation\n",
      "features.4.0.block.3\n",
      "features.4.0.block.3.0\n",
      "features.4.0.block.3.1\n",
      "features.4.0.stochastic_depth\n",
      "features.4.1\n",
      "features.4.1.block\n",
      "features.4.1.block.0\n",
      "features.4.1.block.0.0\n",
      "features.4.1.block.0.1\n",
      "features.4.1.block.0.2\n",
      "features.4.1.block.1\n",
      "features.4.1.block.1.0\n",
      "features.4.1.block.1.1\n",
      "features.4.1.block.1.2\n",
      "features.4.1.block.2\n",
      "features.4.1.block.2.avgpool\n",
      "features.4.1.block.2.fc1\n",
      "features.4.1.block.2.fc2\n",
      "features.4.1.block.2.activation\n",
      "features.4.1.block.2.scale_activation\n",
      "features.4.1.block.3\n",
      "features.4.1.block.3.0\n",
      "features.4.1.block.3.1\n",
      "features.4.1.stochastic_depth\n",
      "features.4.2\n",
      "features.4.2.block\n",
      "features.4.2.block.0\n",
      "features.4.2.block.0.0\n",
      "features.4.2.block.0.1\n",
      "features.4.2.block.0.2\n",
      "features.4.2.block.1\n",
      "features.4.2.block.1.0\n",
      "features.4.2.block.1.1\n",
      "features.4.2.block.1.2\n",
      "features.4.2.block.2\n",
      "features.4.2.block.2.avgpool\n",
      "features.4.2.block.2.fc1\n",
      "features.4.2.block.2.fc2\n",
      "features.4.2.block.2.activation\n",
      "features.4.2.block.2.scale_activation\n",
      "features.4.2.block.3\n",
      "features.4.2.block.3.0\n",
      "features.4.2.block.3.1\n",
      "features.4.2.stochastic_depth\n",
      "features.4.3\n",
      "features.4.3.block\n",
      "features.4.3.block.0\n",
      "features.4.3.block.0.0\n",
      "features.4.3.block.0.1\n",
      "features.4.3.block.0.2\n",
      "features.4.3.block.1\n",
      "features.4.3.block.1.0\n",
      "features.4.3.block.1.1\n",
      "features.4.3.block.1.2\n",
      "features.4.3.block.2\n",
      "features.4.3.block.2.avgpool\n",
      "features.4.3.block.2.fc1\n",
      "features.4.3.block.2.fc2\n",
      "features.4.3.block.2.activation\n",
      "features.4.3.block.2.scale_activation\n",
      "features.4.3.block.3\n",
      "features.4.3.block.3.0\n",
      "features.4.3.block.3.1\n",
      "features.4.3.stochastic_depth\n",
      "features.5\n",
      "features.5.0\n",
      "features.5.0.block\n",
      "features.5.0.block.0\n",
      "features.5.0.block.0.0\n",
      "features.5.0.block.0.1\n",
      "features.5.0.block.0.2\n",
      "features.5.0.block.1\n",
      "features.5.0.block.1.0\n",
      "features.5.0.block.1.1\n",
      "features.5.0.block.1.2\n",
      "features.5.0.block.2\n",
      "features.5.0.block.2.avgpool\n",
      "features.5.0.block.2.fc1\n",
      "features.5.0.block.2.fc2\n",
      "features.5.0.block.2.activation\n",
      "features.5.0.block.2.scale_activation\n",
      "features.5.0.block.3\n",
      "features.5.0.block.3.0\n",
      "features.5.0.block.3.1\n",
      "features.5.0.stochastic_depth\n",
      "features.5.1\n",
      "features.5.1.block\n",
      "features.5.1.block.0\n",
      "features.5.1.block.0.0\n",
      "features.5.1.block.0.1\n",
      "features.5.1.block.0.2\n",
      "features.5.1.block.1\n",
      "features.5.1.block.1.0\n",
      "features.5.1.block.1.1\n",
      "features.5.1.block.1.2\n",
      "features.5.1.block.2\n",
      "features.5.1.block.2.avgpool\n",
      "features.5.1.block.2.fc1\n",
      "features.5.1.block.2.fc2\n",
      "features.5.1.block.2.activation\n",
      "features.5.1.block.2.scale_activation\n",
      "features.5.1.block.3\n",
      "features.5.1.block.3.0\n",
      "features.5.1.block.3.1\n",
      "features.5.1.stochastic_depth\n",
      "features.5.2\n",
      "features.5.2.block\n",
      "features.5.2.block.0\n",
      "features.5.2.block.0.0\n",
      "features.5.2.block.0.1\n",
      "features.5.2.block.0.2\n",
      "features.5.2.block.1\n",
      "features.5.2.block.1.0\n",
      "features.5.2.block.1.1\n",
      "features.5.2.block.1.2\n",
      "features.5.2.block.2\n",
      "features.5.2.block.2.avgpool\n",
      "features.5.2.block.2.fc1\n",
      "features.5.2.block.2.fc2\n",
      "features.5.2.block.2.activation\n",
      "features.5.2.block.2.scale_activation\n",
      "features.5.2.block.3\n",
      "features.5.2.block.3.0\n",
      "features.5.2.block.3.1\n",
      "features.5.2.stochastic_depth\n",
      "features.5.3\n",
      "features.5.3.block\n",
      "features.5.3.block.0\n",
      "features.5.3.block.0.0\n",
      "features.5.3.block.0.1\n",
      "features.5.3.block.0.2\n",
      "features.5.3.block.1\n",
      "features.5.3.block.1.0\n",
      "features.5.3.block.1.1\n",
      "features.5.3.block.1.2\n",
      "features.5.3.block.2\n",
      "features.5.3.block.2.avgpool\n",
      "features.5.3.block.2.fc1\n",
      "features.5.3.block.2.fc2\n",
      "features.5.3.block.2.activation\n",
      "features.5.3.block.2.scale_activation\n",
      "features.5.3.block.3\n",
      "features.5.3.block.3.0\n",
      "features.5.3.block.3.1\n",
      "features.5.3.stochastic_depth\n",
      "features.6\n",
      "features.6.0\n",
      "features.6.0.block\n",
      "features.6.0.block.0\n",
      "features.6.0.block.0.0\n",
      "features.6.0.block.0.1\n",
      "features.6.0.block.0.2\n",
      "features.6.0.block.1\n",
      "features.6.0.block.1.0\n",
      "features.6.0.block.1.1\n",
      "features.6.0.block.1.2\n",
      "features.6.0.block.2\n",
      "features.6.0.block.2.avgpool\n",
      "features.6.0.block.2.fc1\n",
      "features.6.0.block.2.fc2\n",
      "features.6.0.block.2.activation\n",
      "features.6.0.block.2.scale_activation\n",
      "features.6.0.block.3\n",
      "features.6.0.block.3.0\n",
      "features.6.0.block.3.1\n",
      "features.6.0.stochastic_depth\n",
      "features.6.1\n",
      "features.6.1.block\n",
      "features.6.1.block.0\n",
      "features.6.1.block.0.0\n",
      "features.6.1.block.0.1\n",
      "features.6.1.block.0.2\n",
      "features.6.1.block.1\n",
      "features.6.1.block.1.0\n",
      "features.6.1.block.1.1\n",
      "features.6.1.block.1.2\n",
      "features.6.1.block.2\n",
      "features.6.1.block.2.avgpool\n",
      "features.6.1.block.2.fc1\n",
      "features.6.1.block.2.fc2\n",
      "features.6.1.block.2.activation\n",
      "features.6.1.block.2.scale_activation\n",
      "features.6.1.block.3\n",
      "features.6.1.block.3.0\n",
      "features.6.1.block.3.1\n",
      "features.6.1.stochastic_depth\n",
      "features.6.2\n",
      "features.6.2.block\n",
      "features.6.2.block.0\n",
      "features.6.2.block.0.0\n",
      "features.6.2.block.0.1\n",
      "features.6.2.block.0.2\n",
      "features.6.2.block.1\n",
      "features.6.2.block.1.0\n",
      "features.6.2.block.1.1\n",
      "features.6.2.block.1.2\n",
      "features.6.2.block.2\n",
      "features.6.2.block.2.avgpool\n",
      "features.6.2.block.2.fc1\n",
      "features.6.2.block.2.fc2\n",
      "features.6.2.block.2.activation\n",
      "features.6.2.block.2.scale_activation\n",
      "features.6.2.block.3\n",
      "features.6.2.block.3.0\n",
      "features.6.2.block.3.1\n",
      "features.6.2.stochastic_depth\n",
      "features.6.3\n",
      "features.6.3.block\n",
      "features.6.3.block.0\n",
      "features.6.3.block.0.0\n",
      "features.6.3.block.0.1\n",
      "features.6.3.block.0.2\n",
      "features.6.3.block.1\n",
      "features.6.3.block.1.0\n",
      "features.6.3.block.1.1\n",
      "features.6.3.block.1.2\n",
      "features.6.3.block.2\n",
      "features.6.3.block.2.avgpool\n",
      "features.6.3.block.2.fc1\n",
      "features.6.3.block.2.fc2\n",
      "features.6.3.block.2.activation\n",
      "features.6.3.block.2.scale_activation\n",
      "features.6.3.block.3\n",
      "features.6.3.block.3.0\n",
      "features.6.3.block.3.1\n",
      "features.6.3.stochastic_depth\n",
      "features.6.4\n",
      "features.6.4.block\n",
      "features.6.4.block.0\n",
      "features.6.4.block.0.0\n",
      "features.6.4.block.0.1\n",
      "features.6.4.block.0.2\n",
      "features.6.4.block.1\n",
      "features.6.4.block.1.0\n",
      "features.6.4.block.1.1\n",
      "features.6.4.block.1.2\n",
      "features.6.4.block.2\n",
      "features.6.4.block.2.avgpool\n",
      "features.6.4.block.2.fc1\n",
      "features.6.4.block.2.fc2\n",
      "features.6.4.block.2.activation\n",
      "features.6.4.block.2.scale_activation\n",
      "features.6.4.block.3\n",
      "features.6.4.block.3.0\n",
      "features.6.4.block.3.1\n",
      "features.6.4.stochastic_depth\n",
      "features.7\n",
      "features.7.0\n",
      "features.7.0.block\n",
      "features.7.0.block.0\n",
      "features.7.0.block.0.0\n",
      "features.7.0.block.0.1\n",
      "features.7.0.block.0.2\n",
      "features.7.0.block.1\n",
      "features.7.0.block.1.0\n",
      "features.7.0.block.1.1\n",
      "features.7.0.block.1.2\n",
      "features.7.0.block.2\n",
      "features.7.0.block.2.avgpool\n",
      "features.7.0.block.2.fc1\n",
      "features.7.0.block.2.fc2\n",
      "features.7.0.block.2.activation\n",
      "features.7.0.block.2.scale_activation\n",
      "features.7.0.block.3\n",
      "features.7.0.block.3.0\n",
      "features.7.0.block.3.1\n",
      "features.7.0.stochastic_depth\n",
      "features.7.1\n",
      "features.7.1.block\n",
      "features.7.1.block.0\n",
      "features.7.1.block.0.0\n",
      "features.7.1.block.0.1\n",
      "features.7.1.block.0.2\n",
      "features.7.1.block.1\n",
      "features.7.1.block.1.0\n",
      "features.7.1.block.1.1\n",
      "features.7.1.block.1.2\n",
      "features.7.1.block.2\n",
      "features.7.1.block.2.avgpool\n",
      "features.7.1.block.2.fc1\n",
      "features.7.1.block.2.fc2\n",
      "features.7.1.block.2.activation\n",
      "features.7.1.block.2.scale_activation\n",
      "features.7.1.block.3\n",
      "features.7.1.block.3.0\n",
      "features.7.1.block.3.1\n",
      "features.7.1.stochastic_depth\n",
      "features.8\n",
      "features.8.0\n",
      "features.8.1\n",
      "features.8.2\n",
      "avgpool\n",
      "classifier\n",
      "classifier.0\n",
      "classifier.1\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet18, resnet34, resnet50, efficientnet_b1\n",
    "\n",
    "model = efficientnet_b1()\n",
    "for name, module in model.named_modules():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a3add45fc69f05cc29cf9d44865c28a2c1800260c2b05417b30b97f2c4a51861"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 ('project': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
