
Files already downloaded and verified
Train Epoch: 0 [0/50000 (0%)]	Loss: 13.626831
Train Epoch: 0 [25600/50000 (51%)]	Loss: 3.147184
Epoch 1 took 13.08687138557434 seconds to complete
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
Train Epoch: 0 [0/50000 (0%)]	Loss: 14.302245
Train Epoch: 0 [25600/50000 (51%)]	Loss: 3.203193
Epoch 1 took 13.115479946136475 seconds to complete
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([16, 1000])
Test set: Accuracy: 3599/10000 (36%)
Train Epoch: 1 [0/50000 (0%)]	Loss: 2.148193
Train Epoch: 1 [25600/50000 (51%)]	Loss: 2.161112
Epoch 2 took 13.055342435836792 seconds to complete
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([256, 1000])
torch.Size([16, 1000])
Test set: Accuracy: 4476/10000 (45%)
Train Epoch: 2 [0/50000 (0%)]	Loss: 1.564683
Train Epoch: 0 [0/50000 (0%)]	Loss: 13.549385
Exception in thread NetStatThr:
Traceback (most recent call last):
  File "/usr/lib64/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/usr/lib64/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/nfs/stak/users/noelt/Documents/Project/Large_Margin_Loss_PyTorch-master/envs/project/lib64/python3.6/site-packages/wandb/sdk/wandb_run.py", line 152, in check_network_status
    status_response = self._interface.communicate_network_status()
  File "/nfs/stak/users/noelt/Documents/Project/Large_Margin_Loss_PyTorch-master/envs/project/lib64/python3.6/site-packages/wandb/sdk/interface/interface.py", line 138, in communicate_network_status
    resp = self._communicate_network_status(status)
  File "/nfs/stak/users/noelt/Documents/Project/Large_Margin_Loss_PyTorch-master/envs/project/lib64/python3.6/site-packages/wandb/sdk/interface/interface_shared.py", line 405, in _communicate_network_status
    resp = self._communicate(req, local=True)
  File "/nfs/stak/users/noelt/Documents/Project/Large_Margin_Loss_PyTorch-master/envs/project/lib64/python3.6/site-packages/wandb/sdk/interface/interface_shared.py", line 226, in _communicate
    return self._communicate_async(rec, local=local).get(timeout=timeout)
  File "/nfs/stak/users/noelt/Documents/Project/Large_Margin_Loss_PyTorch-master/envs/project/lib64/python3.6/site-packages/wandb/sdk/interface/interface_shared.py", line 231, in _communicate_async
    raise Exception("The wandb backend process has shutdown")
Exception: The wandb backend process has shutdown