{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "id_one_hot: tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "ood_one_hot: tensor([[0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "        ...,\n",
      "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000]],\n",
      "       device='cuda:0')\n",
      "entering ID margin comp\n",
      "raw id logits: tensor([ 1.3729, -2.7457, -1.4266, -4.0204,  3.0991, 19.9772, -6.5153, -5.0508,\n",
      "        -3.1748, -0.0829], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "raw id distance: tensor([[ 8247854.5000, 16755131.0000, 17341690.0000,  ...,\n",
      "         17377452.0000, 17377464.0000, 17377466.0000],\n",
      "        [ 1320370.2500,  1763338.7500,  2266155.2500,  ...,\n",
      "          2269651.2500,  2269698.5000,  2269756.7500],\n",
      "        [99995992.0000, 99997648.0000, 99997816.0000,  ...,\n",
      "         99997896.0000, 99997896.0000, 99997896.0000],\n",
      "        ...,\n",
      "        [96015320.0000, 97965008.0000, 97965416.0000,  ...,\n",
      "         97966512.0000, 97966512.0000, 97966512.0000],\n",
      "        [ 2990394.2500,  5609617.0000,  5641193.0000,  ...,\n",
      "          5734135.0000,  5736221.5000,  5736319.5000],\n",
      "        [99953328.0000, 99976632.0000, 99976640.0000,  ...,\n",
      "         99976648.0000, 99976648.0000, 99976648.0000]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "entering OOD margin comp\n",
      "raw ood logits: tensor([-4.8021, -4.6060, -3.6566, -4.6150, -5.4013, -7.3514, -0.0349,  4.4509,\n",
      "        -1.6178, 26.9105], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "raw ood distance: tensor([[9.6597e+07, 9.8269e+07, 9.8269e+07,  ..., 9.8269e+07, 9.8269e+07,\n",
      "         9.8269e+07],\n",
      "        [9.2617e+07, 9.5968e+07, 9.5982e+07,  ..., 9.6091e+07, 9.6091e+07,\n",
      "         9.6092e+07],\n",
      "        [4.5946e+05, 7.6421e+05, 8.0021e+05,  ..., 8.3725e+05, 8.3730e+05,\n",
      "         8.3731e+05],\n",
      "        ...,\n",
      "        [9.5818e+07, 9.6283e+07, 9.6827e+07,  ..., 9.7301e+07, 9.7302e+07,\n",
      "         9.7302e+07],\n",
      "        [6.1300e+02, 1.2267e+03, 1.2267e+03,  ..., 1.2267e+03, 1.2267e+03,\n",
      "         1.2267e+03],\n",
      "        [1.6545e+07, 2.8388e+07, 2.8391e+07,  ..., 2.8392e+07, 2.8392e+07,\n",
      "         2.8392e+07]], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "id_one_hot: tensor([[0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "ood_one_hot: tensor([[0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "        ...,\n",
      "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000]],\n",
      "       device='cuda:0')\n",
      "entering ID margin comp\n",
      "raw id logits: tensor([-1.2099, -4.2955, -3.9691, -4.4299, 25.0374, -3.5367, -2.8532, -1.8521,\n",
      "        -5.4717,  2.3941], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "raw id distance: tensor([[9.7151e+07, 9.8553e+07, 9.8554e+07,  ..., 9.8554e+07, 9.8554e+07,\n",
      "         9.8554e+07],\n",
      "        [9.5749e+07, 9.7577e+07, 9.7741e+07,  ..., 9.7767e+07, 9.7767e+07,\n",
      "         9.7767e+07],\n",
      "        [2.2472e+04, 4.4934e+04, 4.4934e+04,  ..., 4.4934e+04, 4.4934e+04,\n",
      "         4.4934e+04],\n",
      "        ...,\n",
      "        [9.4145e+07, 9.6980e+07, 9.6983e+07,  ..., 9.6983e+07, 9.6983e+07,\n",
      "         9.6983e+07],\n",
      "        [6.8214e+07, 8.0997e+07, 8.1030e+07,  ..., 8.1056e+07, 8.1062e+07,\n",
      "         8.1064e+07],\n",
      "        [7.6096e+07, 7.6641e+07, 7.8882e+07,  ..., 8.2369e+07, 8.2432e+07,\n",
      "         8.2434e+07]], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "entering OOD margin comp\n",
      "raw ood logits: tensor([-1.9464, -2.4642, -4.3318, -2.8617,  0.7712,  2.3134, -5.2052, 16.5620,\n",
      "        -0.4253, -1.6381], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "raw ood distance: tensor([[4.8030e+05, 7.7234e+05, 8.1698e+05,  ..., 8.5289e+05, 8.5290e+05,\n",
      "         8.5290e+05],\n",
      "        [3.4846e+02, 6.9763e+02, 6.9763e+02,  ..., 6.9763e+02, 6.9763e+02,\n",
      "         6.9763e+02],\n",
      "        [2.1559e+06, 4.4561e+06, 4.4864e+06,  ..., 4.5331e+06, 4.5342e+06,\n",
      "         4.5342e+06],\n",
      "        ...,\n",
      "        [1.3769e+01, 2.8263e+01, 2.8263e+01,  ..., 2.8263e+01, 2.8263e+01,\n",
      "         2.8263e+01],\n",
      "        [3.7234e+07, 4.5904e+07, 4.7019e+07,  ..., 5.0989e+07, 5.0994e+07,\n",
      "         5.0996e+07],\n",
      "        [1.7415e+06, 1.7618e+06, 2.0543e+06,  ..., 2.3939e+06, 2.3939e+06,\n",
      "         2.3939e+06]], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "id_one_hot: tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "ood_one_hot: tensor([[0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "        ...,\n",
      "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
      "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000]],\n",
      "       device='cuda:0')\n",
      "entering ID margin comp\n",
      "raw id logits: tensor([-1.7365, -2.1907, -4.3905, -1.9453, -0.7455,  0.1163, -4.1417, 17.8515,\n",
      "        -0.9478, -1.3822], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "raw id distance: tensor([[1.9372e+07, 2.6597e+07, 2.7551e+07,  ..., 2.9658e+07, 2.9874e+07,\n",
      "         2.9876e+07],\n",
      "        [3.0833e+07, 4.2467e+07, 4.4376e+07,  ..., 4.5724e+07, 4.5725e+07,\n",
      "         4.5725e+07],\n",
      "        [9.9899e+07, 9.9944e+07, 9.9948e+07,  ..., 9.9948e+07, 9.9948e+07,\n",
      "         9.9948e+07],\n",
      "        ...,\n",
      "        [2.4784e+07, 2.5684e+07, 3.2038e+07,  ..., 3.3915e+07, 3.3915e+07,\n",
      "         3.3915e+07],\n",
      "        [9.9789e+07, 9.9894e+07, 9.9894e+07,  ..., 9.9894e+07, 9.9894e+07,\n",
      "         9.9894e+07],\n",
      "        [5.7747e+00, 1.1811e+01, 1.2145e+01,  ..., 1.2145e+01, 1.2145e+01,\n",
      "         1.2145e+01]], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "entering OOD margin comp\n",
      "raw ood logits: tensor([-1.6316, -4.5100, -2.5999, -0.5844, -0.4896, -5.7175, -1.5261, -1.3296,\n",
      "        -3.8033, 21.6693], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "raw ood distance: tensor([[9.4826e+07, 9.5074e+07, 9.6160e+07,  ..., 9.6545e+07, 9.6547e+07,\n",
      "         9.6548e+07],\n",
      "        [9.4626e+07, 9.5195e+07, 9.6599e+07,  ..., 9.6690e+07, 9.6691e+07,\n",
      "         9.6691e+07],\n",
      "        [8.0122e+06, 1.6605e+07, 1.6749e+07,  ..., 1.6842e+07, 1.6842e+07,\n",
      "         1.6842e+07],\n",
      "        ...,\n",
      "        [4.8164e+00, 1.0391e+01, 1.0391e+01,  ..., 1.0391e+01, 1.0391e+01,\n",
      "         1.0391e+01],\n",
      "        [1.8430e+07, 2.6233e+07, 2.8105e+07,  ..., 2.9324e+07, 2.9325e+07,\n",
      "         2.9325e+07],\n",
      "        [3.6571e+07, 3.8098e+07, 4.5386e+07,  ..., 4.7484e+07, 4.7493e+07,\n",
      "         4.7499e+07]], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "Test set: Accuracy: 99/1000 (10%)\n",
      "Test Set: AUROC: 0.5066002739800348\n",
      "\n",
      "Accuracy: 9.9\n",
      "AUROC: 0.5066002739800348\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\")\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "import copy\n",
    "from torchvision.models import resnet18, resnet34, resnet50, efficientnet_b1\n",
    "from torch.utils import data\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, SGD, RMSprop\n",
    "import numpy as np\n",
    "from large_margin import LargeMarginLoss\n",
    "import time\n",
    "import argparse\n",
    "from data import build_split_datasets\n",
    "import pickle as pkl\n",
    "from random_split_generator import FourWayClassSplit\n",
    "from torch.utils.data import ConcatDataset\n",
    "import datetime\n",
    "from experiment import FeatureExtractor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from large_margin import _get_grad\n",
    "import pandas as pd\n",
    "\n",
    "def test_distance(logits, features, device):\n",
    "    eps = 1e-8\n",
    "\n",
    "    entries = 100\n",
    "    # print(\"logits: {}\".format(logits))\n",
    "    # pd_logits = pd.DataFrame(logits.detach().cpu().numpy())\n",
    "    prob = F.softmax(logits, dim=1)\n",
    "    # print(\"prob: {}\".format(prob))\n",
    "    # pd_prob = pd.DataFrame(prob.detach().cpu().numpy())\n",
    "\n",
    "    max_indices = torch.argmax(prob, dim=1)\n",
    "\n",
    "    pseudo_correct_prob, _ = torch.max(prob, dim=1, keepdim=True)\n",
    "    # print(\"pseudo_correct_prob: {}\".format(pseudo_correct_prob))\n",
    "    # print(\"pseudo_correct_prob shape: {}\".format(pseudo_correct_prob.shape))\n",
    "\n",
    "    pseudo_other_prob = torch.zeros(prob.shape).to(device)\n",
    "    pseudo_other_prob.copy_(prob)\n",
    "    pseudo_other_prob[torch.arange(prob.shape[0]),max_indices] = 0.\n",
    "\n",
    "    # Grabs the next most likely class probabilities\n",
    "    if top_k > 1:\n",
    "        topk_prob, _ = pseudo_other_prob.topk(top_k, dim=1)\n",
    "    else:\n",
    "        topk_prob, _ = pseudo_other_prob.max(dim=1, keepdim=True)\n",
    "\n",
    "    # print(\"pseudo correct prob shape: {}\".format(pseudo_correct_prob.shape))\n",
    "    # print(\"topk_prob shape: {}\".format(topk_prob.shape))\n",
    "\n",
    "    pseudo_diff_prob = pseudo_correct_prob - topk_prob\n",
    "\n",
    "    for i, feature_map in enumerate(features):\n",
    "        if i == len(features)-1:\n",
    "            diff_grad = torch.stack([_get_grad(pseudo_diff_prob[:, i], feature_map) for i in range(top_k)],\n",
    "                                dim=1)\n",
    "            diff_gradnorm = torch.norm(diff_grad, p=2, dim=2)\n",
    "            diff_gradnorm.detach_()\n",
    "            distance = pseudo_diff_prob / (diff_gradnorm + eps)\n",
    "\n",
    "    return distance\n",
    "\n",
    "\n",
    "# TODO: Check that ID margins are larger than OOD margins; this is an empirical sanity check\n",
    "def sanity_test_lm_ls(model, top_k, id_loader, ood_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    anomaly_index = 10\n",
    "    num_classes = 10\n",
    "    anom_pred = []\n",
    "    anom_labels = []\n",
    "    anom_score_sequence = []\n",
    "    pred_sequence = []\n",
    "    target_sequence = []\n",
    "    \n",
    "    for batch_idx, ((id_data, id_target), (ood_data, ood_target)) in enumerate(zip(id_loader, ood_loader)):\n",
    "        ood_target = anomaly_index * torch.ones_like(ood_target)\n",
    "\n",
    "        id_one_hot = torch.zeros(len(id_target), num_classes).scatter_(1, id_target.unsqueeze(1), 1.).float()\n",
    "        ood_one_hot = (1/id_one_hot.shape[1])*torch.ones((len(ood_target), id_one_hot.shape[1])).to(device)\n",
    "        id_one_hot, ood_one_hot = id_one_hot.to(device), ood_one_hot.to(device)\n",
    "\n",
    "        print(\"id_one_hot: {}\".format(id_one_hot))\n",
    "        print(\"ood_one_hot: {}\".format(ood_one_hot))\n",
    "\n",
    "        id_data, id_target   = id_data.to(device), id_target.to(device)\n",
    "        ood_data, ood_target = ood_data.to(device), ood_target.to(device)\n",
    "\n",
    "        model.clear_features()\n",
    "        id_data = id_data.to(device)\n",
    "        id_output, id_features  = model(id_data)\n",
    "        for id_feature in id_features:\n",
    "            id_feature.retain_grad()\n",
    "        #id_features = copy.deepcopy(id_features)\n",
    "        print(\"entering ID margin comp\")\n",
    "\n",
    "        # lm(id_output, id_one_hot, id_features)\n",
    "        # raw_id_distance = lm.get_discriminant()\n",
    "        # id_distance = torch.abs(raw_id_distance)\n",
    "    \n",
    "        print(\"raw id logits: {}\".format(id_output[0,:]))\n",
    "\n",
    "        ###########################\n",
    "        # ID Distance Computation #\n",
    "        ###########################\n",
    "        raw_id_distance = test_distance(id_output, id_features, device)\n",
    "        id_distance = torch.abs(raw_id_distance)\n",
    "\n",
    "\n",
    "        # FOR DEBUG\n",
    "        # pd_id_logits.to_csv('id_logit.csv', header=False, mode='a+')\n",
    "        # pd_id_prob.to_csv('id_prob.csv', header=False, mode='a+')\n",
    "        # pd_id_distance = pd.DataFrame(raw_id_distance.detach().cpu().numpy())\n",
    "        # pd_id_distance.to_csv('id_distance.csv', header=False, mode='a+')\n",
    "\n",
    "\n",
    "        print(\"raw id distance: {}\".format(id_distance)) #[0,:]))\n",
    "\n",
    "        model.clear_features()\n",
    "        ood_output, ood_features = model(ood_data)\n",
    "        for ood_feature in ood_features:\n",
    "            ood_feature.retain_grad()\n",
    "        #ood_features = copy.deepcopy(ood_features)\n",
    "        print(\"entering OOD margin comp\")\n",
    "\n",
    "        # lm(ood_output, ood_one_hot, ood_features)\n",
    "        # raw_ood_distance = lm.get_discriminant()\n",
    "        # ood_distance = torch.abs(raw_ood_distance)\n",
    "\n",
    "        print(\"raw ood logits: {}\".format(ood_output[0,:]))\n",
    "\n",
    "        ############################\n",
    "        # OOD Distance Computation #\n",
    "        ############################\n",
    "        raw_ood_distance = test_distance(ood_output, ood_features, device)\n",
    "        ood_distance = torch.abs(raw_ood_distance)\n",
    "\n",
    "\n",
    "        # FOR DEBUG\n",
    "        # pd_ood_logits.to_csv('ood_logit.csv', header=False, mode='a+')\n",
    "        # pd_ood_prob.to_csv('ood_prob.csv', header=False, mode='a+')\n",
    "        # pd_ood_distance = pd.DataFrame(raw_ood_distance.detach().cpu().numpy())\n",
    "        # pd_ood_distance.to_csv('ood_distance.csv', header=False, mode='a+')\n",
    "\n",
    "\n",
    "        # print(\"id distance (should be same as above): {}\".format(id_distance))\n",
    "        print(\"raw ood distance: {}\".format(ood_distance)) #[0,:]))\n",
    "\n",
    "        ood_pred   = ood_output.argmax(dim=1, keepdim=True)\n",
    "        ood_anom_pred = [1. if ood_pred[i] == anomaly_index else 0. for i in range(len(ood_pred))]\n",
    "\n",
    "        # Compute number of correctly classified id instances\n",
    "        id_pred   = id_output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "        _, id_idx = id_output.max(dim=1)\n",
    "        correct += (id_idx == id_target).sum().item()\n",
    "        id_anom_pred = [1. if id_pred[i] == anomaly_index else 0. for i in range(len(id_pred))]\n",
    "\n",
    "        # Concatenate the list (order matters here)\n",
    "        batch_anom_pred = ood_anom_pred + id_anom_pred\n",
    "        anom_pred = anom_pred + batch_anom_pred\n",
    "\n",
    "        pred_sequence.append(ood_pred)\n",
    "        pred_sequence.append(id_pred)\n",
    "\n",
    "        target_sequence.append(ood_target)\n",
    "        target_sequence.append(id_target)\n",
    "\n",
    "        # Compute anomaly scores\n",
    "        # # Use discriminant (distance) function to compute ood_scores\n",
    "        # ood_distance = torch.abs(ood_distance)\n",
    "        ood_scores, _ = torch.max(-1 * ood_distance, dim=1)\n",
    "        ## print(ood_distance[:,1:].shape)\n",
    "        # ood_scores = torch.norm(ood_distance, p=2, dim=1) #[:,1:], p=2, dim=1)\n",
    "        # print('ood scores: {}'.format(ood_scores))\n",
    "        anom_score_sequence.append(ood_scores)\n",
    "        for i in range(len(ood_target)):\n",
    "            # 1 indicates \"anomaly\"\n",
    "            anom_labels.append(1.)\n",
    "\n",
    "        # Use discriminant function to compute id_scores\n",
    "        # id_distance = torch.abs(id_distance)\n",
    "        id_scores, _ = torch.max(-1 * id_distance, dim=1)\n",
    "        ## print(id_distance[:,1:].shape)\n",
    "        # id_scores = torch.norm(id_distance, p=2, dim=1) #[:,1:], p=2, dim=1)\n",
    "        # print('id scores: {}'.format(id_scores))\n",
    "        anom_score_sequence.append(id_scores)\n",
    "        for i in range(len(id_target)):\n",
    "            # 0 indicates \"nominal\"\n",
    "            anom_labels.append(0.)\n",
    "\n",
    "    anom_scores = torch.hstack(anom_score_sequence).cpu().detach().numpy()\n",
    "    anom_labels = np.asarray(anom_labels)\n",
    "    anom_pred = np.asarray(anom_pred)\n",
    "    pred = torch.vstack(pred_sequence).cpu().detach().numpy()\n",
    "    pred = np.ndarray.flatten(pred)\n",
    "    targets = torch.hstack(target_sequence).cpu().detach().numpy()\n",
    "\n",
    "    AUROC = roc_auc_score(anom_labels, anom_scores)\n",
    "\n",
    "    accuracy = 100. * correct / len(id_loader.dataset)\n",
    "    print('Test set: Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        correct, len(id_loader.dataset), accuracy))\n",
    "    print('Test Set: AUROC: {}\\n'.format(AUROC))\n",
    "\n",
    "    return accuracy, AUROC, id_distance, ood_distance\n",
    "\n",
    "\n",
    "PATH = '/nfs/stak/users/noelt/Documents/Project/noelt_masters_project/models/margin_LS_oe_test/day_7_25_time_4_20_split_4_epoch_295.pth'\n",
    "batch_size=256\n",
    "\n",
    "# Right now, hardcoded to use CIFAR-100, with hardcoded splits\n",
    "# defined and generated in random_split_generator.py\n",
    "id_data, ood_data = build_split_datasets(0, False)\n",
    "\n",
    "id_train_data, id_val_data, id_test_data    = id_data\n",
    "ood_train_data, ood_val_data, ood_test_data = ood_data\n",
    "\n",
    "# Constructing Dataloaders\n",
    "id_train_loader = data.DataLoader(id_train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "id_val_loader   = data.DataLoader(id_val_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "id_test_loader   = data.DataLoader(id_test_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "ood_train_loader   = data.DataLoader(ood_train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "ood_val_loader   = data.DataLoader(ood_val_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "ood_test_loader   = data.DataLoader(ood_test_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "model = FeatureExtractor(\"efficientnet_b1\", 10)\n",
    "model.load_state_dict(torch.load(PATH)['model_state_dict'])\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "\n",
    "top_k=9\n",
    "\n",
    "lm = LargeMarginLoss(\n",
    "    gamma=19600,\n",
    "    alpha_factor=7,\n",
    "    top_k=top_k,\n",
    "    dist_norm=2\n",
    ")\n",
    "\n",
    "acc, auc, id_dist, ood_dist = sanity_test_lm_ls(model, top_k, id_val_loader, ood_val_loader, device)\n",
    "\n",
    "print(\"Accuracy: {}\".format(acc))\n",
    "print(\"AUROC: {}\".format(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 ('project': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a3add45fc69f05cc29cf9d44865c28a2c1800260c2b05417b30b97f2c4a51861"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
